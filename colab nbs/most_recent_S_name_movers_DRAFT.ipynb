{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["epqaV4bo4uuI","SQGsnfqCzLeb","KWg1JNNpxugn"],"gpuType":"T4","authorship_tag":"ABX9TyMIPV04KzW5sSlPHzcl9jw/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"478e0ad70f9c45adb922732b756f1484":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_987875c2e0e04f168ad9da9c4475844a","IPY_MODEL_bb5c3991ba0b413bb3bc4ba82b735f3e","IPY_MODEL_f73b73ccec6f47af8d021deac09d3dcc"],"layout":"IPY_MODEL_8820e306711d43f28aafefb9a3cf15fa"}},"987875c2e0e04f168ad9da9c4475844a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ba75628bda143c8b1635182fc7ef045","placeholder":"​","style":"IPY_MODEL_7cd85397a38741bbac2436bb8ecde2db","value":"Downloading (…)lve/main/config.json: 100%"}},"bb5c3991ba0b413bb3bc4ba82b735f3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9780350bbfec4231af5af4850c43a1f3","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bdccb5cb2804926815ebbaaeb36b117","value":665}},"f73b73ccec6f47af8d021deac09d3dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1797be0fbb004c5ea20ff200cb811641","placeholder":"​","style":"IPY_MODEL_134c1169ad5e4ad4baf8f1e644636288","value":" 665/665 [00:00&lt;00:00, 21.6kB/s]"}},"8820e306711d43f28aafefb9a3cf15fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ba75628bda143c8b1635182fc7ef045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cd85397a38741bbac2436bb8ecde2db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9780350bbfec4231af5af4850c43a1f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bdccb5cb2804926815ebbaaeb36b117":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1797be0fbb004c5ea20ff200cb811641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"134c1169ad5e4ad4baf8f1e644636288":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14c9b75b832341f8b93ca64c86e619b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4624cddfab5c458a9a0bb5699bac90c1","IPY_MODEL_368a4e5fe9684774ab38ce7ab3d580ce","IPY_MODEL_14fa005ddecf48f2957a816249e1ded8"],"layout":"IPY_MODEL_21568397297e4cf3b050ce7b70a57267"}},"4624cddfab5c458a9a0bb5699bac90c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d938f62a93be4926ba48ba50c291c543","placeholder":"​","style":"IPY_MODEL_0bc82fd421de4b989320a5b1e2f4999c","value":"Downloading model.safetensors: 100%"}},"368a4e5fe9684774ab38ce7ab3d580ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c5cf4275fd54510a21096b940e1a91f","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdcede7b80204f73a5812d96de73a6f7","value":548105171}},"14fa005ddecf48f2957a816249e1ded8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef88966915cc408c8ab2ad39b4ee321c","placeholder":"​","style":"IPY_MODEL_6989e927bd0e486ba023392a6b413242","value":" 548M/548M [00:02&lt;00:00, 232MB/s]"}},"21568397297e4cf3b050ce7b70a57267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d938f62a93be4926ba48ba50c291c543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bc82fd421de4b989320a5b1e2f4999c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c5cf4275fd54510a21096b940e1a91f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdcede7b80204f73a5812d96de73a6f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef88966915cc408c8ab2ad39b4ee321c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6989e927bd0e486ba023392a6b413242":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c304e9b994454fc882e4d1b416eef938":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f8d9a2f7a614b148f6b8b61a1c9d1f4","IPY_MODEL_d01ceedc753a49bf8c027bd9241fe34d","IPY_MODEL_3e7b00299d564bf782201880b655730a"],"layout":"IPY_MODEL_4191d544c3204a95bf4ccddb586a1f6b"}},"3f8d9a2f7a614b148f6b8b61a1c9d1f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2111c7a7b9d6493f81e4eab61974ec57","placeholder":"​","style":"IPY_MODEL_956cff6a162e4cddb00d1109baaf7b93","value":"Downloading (…)neration_config.json: 100%"}},"d01ceedc753a49bf8c027bd9241fe34d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f163eb827634e62b6b2557b1be8003f","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61975b969ad54e3fa3ba98b66783c727","value":124}},"3e7b00299d564bf782201880b655730a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cabc0587944f4dec956130db5b6428ec","placeholder":"​","style":"IPY_MODEL_aa482083146a483b91b37534675b9449","value":" 124/124 [00:00&lt;00:00, 1.82kB/s]"}},"4191d544c3204a95bf4ccddb586a1f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2111c7a7b9d6493f81e4eab61974ec57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"956cff6a162e4cddb00d1109baaf7b93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f163eb827634e62b6b2557b1be8003f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61975b969ad54e3fa3ba98b66783c727":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cabc0587944f4dec956130db5b6428ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa482083146a483b91b37534675b9449":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"200725cf398247df99e33e48bd3241d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1caa2f2b0ebb485396da25aa2a783601","IPY_MODEL_09e25dfd071441899031026ae408d41b","IPY_MODEL_8d3da85407594b7092f3fa32235f070f"],"layout":"IPY_MODEL_a7b7ff7a4fff4a11bd401cf2180bdc64"}},"1caa2f2b0ebb485396da25aa2a783601":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05188a7f4f054207ae7fec9d18278cc9","placeholder":"​","style":"IPY_MODEL_7f97fed7c3d74382ae1334f335512030","value":"Downloading (…)olve/main/vocab.json: 100%"}},"09e25dfd071441899031026ae408d41b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48e70f486f804b19a4b47b4521972b10","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e9fd2f4b193455398abfc8debda25a5","value":1042301}},"8d3da85407594b7092f3fa32235f070f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdf1715ff34e46959a3fb0f41b67db68","placeholder":"​","style":"IPY_MODEL_89f8c8aeabb3400b880d97320a51787f","value":" 1.04M/1.04M [00:00&lt;00:00, 4.10MB/s]"}},"a7b7ff7a4fff4a11bd401cf2180bdc64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05188a7f4f054207ae7fec9d18278cc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f97fed7c3d74382ae1334f335512030":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48e70f486f804b19a4b47b4521972b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e9fd2f4b193455398abfc8debda25a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdf1715ff34e46959a3fb0f41b67db68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89f8c8aeabb3400b880d97320a51787f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af32de4d90064cdb872abd7ad77da4c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7184958a2fa14d4eba2ccad415a4208a","IPY_MODEL_7a9ba853db3541c79d8a55b8c4161274","IPY_MODEL_99e56651e36e424aac54a0ee40652c8b"],"layout":"IPY_MODEL_bc0834d87719458a8da069d2a118f19f"}},"7184958a2fa14d4eba2ccad415a4208a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3092f91d4c0a4fa1814ab38c5dab56b0","placeholder":"​","style":"IPY_MODEL_a1852ee0f8a54529954e1b72789e61d7","value":"Downloading (…)olve/main/merges.txt: 100%"}},"7a9ba853db3541c79d8a55b8c4161274":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f143a9140af4a3dbe9f5ff9123862fa","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aec88c51fd2c44dca82366785776c1b3","value":456318}},"99e56651e36e424aac54a0ee40652c8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d9abe99eb4491dafe3d7b565290c70","placeholder":"​","style":"IPY_MODEL_3c4c2fe0a5b8433fa967161c05c384f4","value":" 456k/456k [00:00&lt;00:00, 1.86MB/s]"}},"bc0834d87719458a8da069d2a118f19f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3092f91d4c0a4fa1814ab38c5dab56b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1852ee0f8a54529954e1b72789e61d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f143a9140af4a3dbe9f5ff9123862fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aec88c51fd2c44dca82366785776c1b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7d9abe99eb4491dafe3d7b565290c70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c4c2fe0a5b8433fa967161c05c384f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d4ec20e79fb4e1086d5706bcc86df5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f78b3820095e41a09c9d859af37b1614","IPY_MODEL_c77dc9154f5248af830725d3b7d06238","IPY_MODEL_bc99a57e1db14e7ba33f74b0769ef9ab"],"layout":"IPY_MODEL_cedc4dcbc55643fa8c18b447ea54c9b6"}},"f78b3820095e41a09c9d859af37b1614":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eaf89f5f69d42bb9083c44a9579369b","placeholder":"​","style":"IPY_MODEL_9c1a5ec1b5b745499d406a7018679ca2","value":"Downloading (…)/main/tokenizer.json: 100%"}},"c77dc9154f5248af830725d3b7d06238":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_580e78dc1db04615a63b0b38f9950744","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_663a85645ec64ed381d23e6cc30aff61","value":1355256}},"bc99a57e1db14e7ba33f74b0769ef9ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fd58179d2f0404c97ee8a82d715139b","placeholder":"​","style":"IPY_MODEL_9605301d5b6f4586b657fcf409180b42","value":" 1.36M/1.36M [00:00&lt;00:00, 4.12MB/s]"}},"cedc4dcbc55643fa8c18b447ea54c9b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eaf89f5f69d42bb9083c44a9579369b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c1a5ec1b5b745499d406a7018679ca2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"580e78dc1db04615a63b0b38f9950744":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"663a85645ec64ed381d23e6cc30aff61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fd58179d2f0404c97ee8a82d715139b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9605301d5b6f4586b657fcf409180b42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"epqaV4bo4uuI"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3ANUnkaP41tk","executionInfo":{"status":"ok","timestamp":1687966183997,"user_tz":240,"elapsed":31194,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["%%capture\n","# %pip install git+https://github.com/redwoodresearch/Easy-Transformer.git\n","%pip install git+https://github.com/wlg1/Easy-Transformer.git\n","%pip install einops datasets transformers fancy_einsum"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rmhOgC9o4uuI","executionInfo":{"status":"ok","timestamp":1687966191209,"user_tz":240,"elapsed":7218,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from copy import deepcopy\n","import torch\n","\n","# assert torch.cuda.device_count() == 1\n","from tqdm import tqdm\n","import pandas as pd\n","import torch\n","import torch as t\n","from easy_transformer.EasyTransformer import (\n","    EasyTransformer,\n",")\n","from time import ctime\n","from functools import partial\n","\n","import numpy as np\n","from tqdm import tqdm\n","import pandas as pd\n","\n","from easy_transformer.experiments import (\n","    ExperimentMetric,\n","    AblationConfig,\n","    EasyAblation,\n","    EasyPatching,\n","    PatchingConfig,\n",")\n","import plotly.express as px\n","import plotly.io as pio\n","import plotly.graph_objects as go\n","import random\n","import einops\n","from IPython import get_ipython\n","from copy import deepcopy\n","from easy_transformer.ioi_dataset import (\n","    IOIDataset,\n",")\n","from easy_transformer.ioi_utils import (\n","    path_patching,\n","    max_2d,\n","    CLASS_COLORS,\n","    show_pp,\n","    show_attention_patterns,\n","    scatter_attention_and_contribution,\n",")\n","from random import randint as ri\n","from easy_transformer.ioi_circuit_extraction import (\n","    do_circuit_extraction,\n","    get_heads_circuit,\n","    CIRCUIT,\n",")\n","from easy_transformer.ioi_utils import logit_diff, probs\n","from easy_transformer.ioi_utils import get_top_tokens_and_probs as g\n","\n","ipython = get_ipython()\n","if ipython is not None:\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"markdown","metadata":{"id":"q2AuFrzz4uuJ"},"source":[" Initialise model (use larger N or fewer templates for no warnings about in-template ablation)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["478e0ad70f9c45adb922732b756f1484","987875c2e0e04f168ad9da9c4475844a","bb5c3991ba0b413bb3bc4ba82b735f3e","f73b73ccec6f47af8d021deac09d3dcc","8820e306711d43f28aafefb9a3cf15fa","8ba75628bda143c8b1635182fc7ef045","7cd85397a38741bbac2436bb8ecde2db","9780350bbfec4231af5af4850c43a1f3","7bdccb5cb2804926815ebbaaeb36b117","1797be0fbb004c5ea20ff200cb811641","134c1169ad5e4ad4baf8f1e644636288","14c9b75b832341f8b93ca64c86e619b8","4624cddfab5c458a9a0bb5699bac90c1","368a4e5fe9684774ab38ce7ab3d580ce","14fa005ddecf48f2957a816249e1ded8","21568397297e4cf3b050ce7b70a57267","d938f62a93be4926ba48ba50c291c543","0bc82fd421de4b989320a5b1e2f4999c","2c5cf4275fd54510a21096b940e1a91f","fdcede7b80204f73a5812d96de73a6f7","ef88966915cc408c8ab2ad39b4ee321c","6989e927bd0e486ba023392a6b413242","c304e9b994454fc882e4d1b416eef938","3f8d9a2f7a614b148f6b8b61a1c9d1f4","d01ceedc753a49bf8c027bd9241fe34d","3e7b00299d564bf782201880b655730a","4191d544c3204a95bf4ccddb586a1f6b","2111c7a7b9d6493f81e4eab61974ec57","956cff6a162e4cddb00d1109baaf7b93","1f163eb827634e62b6b2557b1be8003f","61975b969ad54e3fa3ba98b66783c727","cabc0587944f4dec956130db5b6428ec","aa482083146a483b91b37534675b9449","200725cf398247df99e33e48bd3241d7","1caa2f2b0ebb485396da25aa2a783601","09e25dfd071441899031026ae408d41b","8d3da85407594b7092f3fa32235f070f","a7b7ff7a4fff4a11bd401cf2180bdc64","05188a7f4f054207ae7fec9d18278cc9","7f97fed7c3d74382ae1334f335512030","48e70f486f804b19a4b47b4521972b10","2e9fd2f4b193455398abfc8debda25a5","bdf1715ff34e46959a3fb0f41b67db68","89f8c8aeabb3400b880d97320a51787f","af32de4d90064cdb872abd7ad77da4c1","7184958a2fa14d4eba2ccad415a4208a","7a9ba853db3541c79d8a55b8c4161274","99e56651e36e424aac54a0ee40652c8b","bc0834d87719458a8da069d2a118f19f","3092f91d4c0a4fa1814ab38c5dab56b0","a1852ee0f8a54529954e1b72789e61d7","5f143a9140af4a3dbe9f5ff9123862fa","aec88c51fd2c44dca82366785776c1b3","f7d9abe99eb4491dafe3d7b565290c70","3c4c2fe0a5b8433fa967161c05c384f4","1d4ec20e79fb4e1086d5706bcc86df5a","f78b3820095e41a09c9d859af37b1614","c77dc9154f5248af830725d3b7d06238","bc99a57e1db14e7ba33f74b0769ef9ab","cedc4dcbc55643fa8c18b447ea54c9b6","0eaf89f5f69d42bb9083c44a9579369b","9c1a5ec1b5b745499d406a7018679ca2","580e78dc1db04615a63b0b38f9950744","663a85645ec64ed381d23e6cc30aff61","4fd58179d2f0404c97ee8a82d715139b","9605301d5b6f4586b657fcf409180b42"],"height":301},"executionInfo":{"elapsed":17434,"status":"ok","timestamp":1687966208638,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"J_cd_q8q4uuK","outputId":"bd365ff5-5ad3-42a4-fd2d-df0266be436e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478e0ad70f9c45adb922732b756f1484"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c9b75b832341f8b93ca64c86e619b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c304e9b994454fc882e4d1b416eef938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"200725cf398247df99e33e48bd3241d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af32de4d90064cdb872abd7ad77da4c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d4ec20e79fb4e1086d5706bcc86df5a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easy_transformer/components.py:616: UserWarning: Moved LN1 to the attention block\n","  warnings.warn(\"Moved LN1 to the attention block\")\n"]},{"output_type":"stream","name":"stdout","text":["Moving model to device:  cuda\n","Finished loading pretrained model gpt2 into EasyTransformer!\n"]}],"source":["# model = EasyTransformer.from_pretrained(\"gpt2\").cuda()\n","model = EasyTransformer.from_pretrained(\"gpt2\")\n","model.set_use_attn_result(True)"]},{"cell_type":"markdown","metadata":{"id":"YaJBj52XWzMP"},"source":["# Dataset of Prompts"]},{"cell_type":"markdown","metadata":{"id":"8g-ZumulbuPN"},"source":["https://github.com/redwoodresearch/Easy-Transformer/blob/main/easy_transformer/ioi_dataset.py\n","\n","See:\n","class IOIDataset:\n","...\n","\n","elif isinstance(prompt_type, list):\n","    self.templates = prompt_type\n","\n","prompt type is required, and this is how it uses custom"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3045,"status":"ok","timestamp":1685844923718,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"wsgXK6jvbE-s","outputId":"50733b2f-2046-466a-9313-536b0c49023f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py:501: UserWarning: S2 index has been computed as the same for S and S2\n","  warnings.warn(\"S2 index has been computed as the same for S and S2\")\n"]}],"source":["N=10\n","custom_templates = [\n","    \" The human is [A]. The animal is [B]. The human is\",\n","]\n","# IOIDataset imported from lib\n","dataset = IOIDataset(prompt_type=custom_templates, N=N, tokenizer=model.tokenizer, prepend_bos=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1685116525384,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"REMYeYuUc1Gi","outputId":"f4ed7ef9-f82f-4960-cc4d-1cbd42de795d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' The human is John. The animal is Amy. The human is',\n"," ' The human is Jeffrey. The animal is Richard. The human is',\n"," ' The human is Sara. The animal is Christine. The human is']"]},"metadata":{},"execution_count":7}],"source":["dataset.sentences[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ3H1QrM4uuL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685116592209,"user_tz":240,"elapsed":5568,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"81521d0c-24af-4e79-b18e-bf995cfc0963"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model gets average logit difference 1.0955629348754883 over 10 examples\n","The model gets average IO probs 1.6234673239523545e-05 over 10 examples\n"]}],"source":["model_logit_diff = logit_diff(model, dataset)\n","model_io_probs = probs(model, dataset)\n","print(\n","    f\"The model gets average logit difference {model_logit_diff.item()} over {N} examples\"\n",")\n","print(f\"The model gets average IO probs {model_io_probs.item()} over {N} examples\")"]},{"cell_type":"markdown","metadata":{"id":"dmnpvUF-4uuN"},"source":["# Copy score"]},{"cell_type":"code","source":["cache = {}\n","model.cache_some(cache, lambda x: x == \"blocks.0.hook_resid_post\")\n","model(dataset.toks.long())\n","z_0 = model.blocks[1].attn.ln1(cache[\"blocks.0.hook_resid_post\"])"],"metadata":{"id":"719x4FjJyzV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z_0.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vG8ZB6gKzVVD","executionInfo":{"status":"ok","timestamp":1685654486556,"user_tz":240,"elapsed":244,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ef48631b-2126-4e03-f685-a193fffca5ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 13, 768])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["layer, head = 9, 9\n","model.blocks[layer].attn.W_V[head].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1SoVlTv8sGc","executionInfo":{"status":"ok","timestamp":1685654493854,"user_tz":240,"elapsed":511,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"98b977c3-72c4-4f37-e89d-c027333919a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([768, 64])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["model.blocks[layer].attn.W_O[head].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4aZLzWn18_n","executionInfo":{"status":"ok","timestamp":1685654593950,"user_tz":240,"elapsed":413,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"63c7687f-7909-4402-d2c6-d0a36fd86b09"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 768])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["model.blocks[layer].attn.W_O[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqYs4cJ694V5","executionInfo":{"status":"ok","timestamp":1685656671921,"user_tz":240,"elapsed":247,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"94b4b3bc-0439-4c4e-85b7-d6150c03953b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.1318, -0.1279,  0.0167,  ..., -0.0699, -0.0487, -0.1682],\n","        [ 0.2072, -0.0121,  0.1069,  ...,  0.0012,  0.1675,  0.0476],\n","        [-0.0355,  0.1091,  0.1889,  ..., -0.0576,  0.1558,  0.0071],\n","        ...,\n","        [-0.0205, -0.0530, -0.0531,  ..., -0.0044,  0.2247,  0.0134],\n","        [ 0.0336, -0.1307, -0.0625,  ...,  0.1310,  0.2081, -0.1060],\n","        [ 0.0877, -0.1131, -0.0253,  ..., -0.0442,  0.0106,  0.0341]],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["model.blocks[layer].attn.W_O[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gffQgsdW96K6","executionInfo":{"status":"ok","timestamp":1685656678991,"user_tz":240,"elapsed":254,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"49678309-bed9-4e3e-f5ef-a283ca86a876"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.1124,  0.1710,  0.0596,  ..., -0.1461,  0.0331, -0.1071],\n","        [-0.0867, -0.1263,  0.0233,  ..., -0.1319,  0.2095,  0.1257],\n","        [ 0.0527,  0.1728, -0.0175,  ...,  0.3649, -0.0555,  0.1738],\n","        ...,\n","        [ 0.0726, -0.1843, -0.1738,  ...,  0.1236,  0.3114, -0.2309],\n","        [ 0.1949, -0.0181, -0.0466,  ..., -0.2510, -0.1156,  0.0460],\n","        [ 0.1459,  0.1847,  0.0088,  ...,  0.1253,  0.0934, -0.2282]],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["dir(model.blocks[9].attn)"],"metadata":{"id":"jzkQ-s_B6c42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.blocks[9].mlp"],"metadata":{"id":"smMtWavm7Ksj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.toks.long().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxDGF3dwMMCF","executionInfo":{"status":"ok","timestamp":1685844975261,"user_tz":240,"elapsed":251,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1b5ebbcd-f000-447f-a537-133910e2f6cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 13])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"ogxROGvb8tOy"}},{"cell_type":"code","source":["def check_copy_circuit(model, layer, head, ioi_dataset, verbose=False, neg=False):\n","    cache = {}\n","    model.cache_some(cache, lambda x: x == \"blocks.0.hook_resid_post\")\n","    model(ioi_dataset.toks.long())\n","    if neg:\n","        sign = -1\n","    else:\n","        sign = 1\n","    z_0 = model.blocks[1].attn.ln1(cache[\"blocks.0.hook_resid_post\"])\n","\n","    v = torch.einsum(\"eab,bc->eac\", z_0, model.blocks[layer].attn.W_V[head])\n","    v += model.blocks[layer].attn.b_V[head].unsqueeze(0).unsqueeze(0)\n","\n","    o = sign * torch.einsum(\"sph,hd->spd\", v, model.blocks[layer].attn.W_O[head])\n","    logits = model.unembed(model.ln_final(o))\n","\n","    k = 5\n","    n_right = 0\n","\n","    for seq_idx, prompt in enumerate(ioi_dataset.ioi_prompts):\n","        for word in [\"IO\", \"S\", \"S2\"]:\n","            pred_tokens = [\n","                model.tokenizer.decode(token)\n","                for token in torch.topk(\n","                    logits[seq_idx, ioi_dataset.word_idx[word][seq_idx]], k\n","                ).indices\n","            ]\n","            if \"S\" in word:\n","                name = \"S\"\n","            else:\n","                name = word\n","            if \" \" + prompt[name] in pred_tokens:\n","                n_right += 1\n","            else:\n","                if verbose:\n","                    print(\"-------\")\n","                    print(\"Seq: \" + ioi_dataset.sentences[seq_idx])\n","                    print(\"Target: \" + ioi_dataset.ioi_prompts[seq_idx][name])\n","                    print(\n","                        \" \".join(\n","                            [\n","                                f\"({i+1}):{model.tokenizer.decode(token)}\"\n","                                for i, token in enumerate(\n","                                    torch.topk(\n","                                        logits[\n","                                            seq_idx, ioi_dataset.word_idx[word][seq_idx]\n","                                        ],\n","                                        k,\n","                                    ).indices\n","                                )\n","                            ]\n","                        )\n","                    )\n","    percent_right = (n_right / (ioi_dataset.N * 3)) * 100\n","    # print(\n","    #     f\"Copy circuit for head {layer}.{head} (sign={sign}) : Top {k} accuracy: {percent_right}%\"\n","    # )\n","    print(\n","        f\"Copy circuit for head {layer}.{head} (sign={sign}) : {pred_tokens}%\"\n","    )\n","    return percent_right, pred_tokens"],"metadata":{"id":"PfKSpSSgx7Kx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["check_copy_circuit(model, 9, 9, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53Nh-LWryBXy","executionInfo":{"status":"ok","timestamp":1685395476192,"user_tz":240,"elapsed":1792,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e6918d9a-d161-42ff-896e-ffa6d86b7ccd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.9 (sign=1) : [' Kristen', 'Krist', ' Stewart', ' Krist', ' Stefan']%\n"]},{"output_type":"execute_result","data":{"text/plain":["(100.0, [' Kristen', 'Krist', ' Stewart', ' Krist', ' Stefan'])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["N=2\n","custom_templates = [\n","    \"[A] is a teacher. [B] is a student. The child is [B]. [C] is a teacher. [D] is a student. The child is\",\n","]\n","dataset2 = IOIDataset(prompt_type=custom_templates, N=N, tokenizer=model.tokenizer, prepend_bos=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"ocdvug10arXv","executionInfo":{"status":"error","timestamp":1685395920840,"user_tz":240,"elapsed":545,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"48928bad-6ac5-41e2-dfa4-20d75767ffa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py:769: UserWarning: Some groups have less than 5 prompts, they have lengths [2]\n","  warnings.warn(\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-bfdb86c3f9f7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"[A] is a teacher. [B] is a student. The child is [B]. [C] is a teacher. [D] is a student. The child is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIOIDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_templates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_bos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, prompt_type, N, tokenizer, prompts, symmetric, prefixes, nb_templates, ioi_prompts_for_word_idxs, prepend_bos, manual_word_idx)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioi_prompts_for_word_idxs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mioi_prompts_for_word_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioi_prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         self.word_idx = get_idx_dict(\n\u001b[0m\u001b[1;32m    798\u001b[0m             \u001b[0mioi_prompts_for_word_idxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py\u001b[0m in \u001b[0;36mget_idx_dict\u001b[0;34m(ioi_prompts, tokenizer, prepend_bos, toks)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_idx_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_bos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     (IO_idxs, S_idxs, S2_idxs,) = get_name_idxs(\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0mioi_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py\u001b[0m in \u001b[0;36mget_name_idxs\u001b[0;34m(prompts, tokenizer, idx_types, prepend_bos)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 )\n\u001b[1;32m    494\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mname_idx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"S\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"S2\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 'ĠJohn' is not in list"]}]},{"cell_type":"markdown","source":["```\n","def get_name_idxs(prompts, tokenizer, idx_types=[\"IO\", \"S\", \"S2\"], prepend_bos=False):\n","```\n","\n","ISSUE: IOIdataset only allows 3 specific types of subjects"],"metadata":{"id":"XgIOkmz4aIwO"}},{"cell_type":"markdown","source":["## Rewrite copy scores and dataset"],"metadata":{"id":"AUz499n4zhsm"}},{"cell_type":"markdown","source":["Given that the ioi_dataset class just stores things to be called by copy scores and path patching, you can not use that class and use your own class, as ioi_dataset has certain requirements\n","\n","First, find what's being called in copy scores, so they can be emulated in your new object"],"metadata":{"id":"B6UfCapwzwNd"}},{"cell_type":"markdown","source":["### Explore IOIdataset's vars"],"metadata":{"id":"CwBj0DbZNGkF"}},{"cell_type":"code","source":["N=2\n","custom_templates = [\n","    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n","]\n","dataset = IOIDataset(prompt_type=custom_templates, N=N, tokenizer=model.tokenizer, prepend_bos=False)"],"metadata":{"id":"yYWCIUODjWCw","executionInfo":{"status":"ok","timestamp":1685405638245,"user_tz":240,"elapsed":187,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f165649c-9797-4b7d-8a2c-cdc32c9ef6b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py:769: UserWarning: Some groups have less than 5 prompts, they have lengths [2]\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["vars(dataset).keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fK-0vOEHu9M","executionInfo":{"status":"ok","timestamp":1685398198400,"user_tz":240,"elapsed":563,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"df4db5d5-415c-447d-c357-e1024c59d2f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['prompt_type', 'templates', 'tokenizer', 'prefixes', 'ioi_prompts', 'groups', 'sentences', 'templates_by_prompt', 'toks', 'word_idx', 'prepend_bos', 'sem_tok_idx', 'N', 'max_len', 'io_tokenIDs', 's_tokenIDs', 'tokenized_prompts'])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["dataset.toks.long().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qM7MnywIzf4b","executionInfo":{"status":"ok","timestamp":1685398199469,"user_tz":240,"elapsed":240,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ea193a21-1087-4252-dc07-902ea80a9886"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 24])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["#for seq_idx, prompt in enumerate(ioi_dataset.ioi_prompts):\n","dataset.ioi_prompts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fxY6ux8zn29","executionInfo":{"status":"ok","timestamp":1685398201065,"user_tz":240,"elapsed":429,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0f7f7ada-7f3d-4226-fbe3-df0aefdc5eff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'[PLACE]': 'restaurant',\n","  '[OBJECT]': 'ring',\n","  'text': 'Then, Sarah, Jeffrey and [C] went to the restaurant. Jeffrey and [C] gave a ring to Sarah',\n","  'IO': 'Sarah',\n","  'S': 'Jeffrey',\n","  'TEMPLATE_IDX': 0},\n"," {'[PLACE]': 'office',\n","  '[OBJECT]': 'computer',\n","  'text': 'Then, Sean, Jessica and [C] went to the office. Jessica and [C] gave a computer to Sean',\n","  'IO': 'Sean',\n","  'S': 'Jessica',\n","  'TEMPLATE_IDX': 0}]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["dataset.word_idx['S'][0]  # token position includes punctuation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEz3dClW0kLO","executionInfo":{"status":"ok","timestamp":1685398262657,"user_tz":240,"elapsed":9,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"26d34439-53a1-46c3-97b9-f7d042739c72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["dataset.word_idx['S'][0].item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-6kEXPSh-_u","executionInfo":{"status":"ok","timestamp":1685398264564,"user_tz":240,"elapsed":460,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b0491121-f02d-4c7f-8ad1-47041dd424f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["dataset.word_idx"],"metadata":{"id":"2vslk6WVyU9O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685398266973,"user_tz":240,"elapsed":271,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0517c8c8-cfbd-46ab-a22d-c8401cf8fb15"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'IO': tensor([2, 2]),\n"," 'IO-1': tensor([1, 1]),\n"," 'IO+1': tensor([3, 3]),\n"," 'S': tensor([4, 4]),\n"," 'S-1': tensor([3, 3]),\n"," 'S+1': tensor([5, 5]),\n"," 'S2': tensor([14, 14]),\n"," 'end': tensor([22, 22]),\n"," 'starts': tensor([0, 0]),\n"," 'punct': tensor([13, 13])}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["dataset.toks.long().shape[1] - 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-twA19s6ADSs","executionInfo":{"status":"ok","timestamp":1685405650444,"user_tz":240,"elapsed":455,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d5e1fe71-a7cb-4964-c539-bbe20f3287c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":168}]},{"cell_type":"markdown","source":["So you don't need place or object in each prompt. The S and IO are replaced by S1, S2, etc. and the most recent (S4) should be the answer. We aim to find which heads copy scores include S4; these are name movers that move S4 to the output (contributing much to how it becomes the top logit by the final layer)."],"metadata":{"id":"-b0SLm6t2CoR"}},{"cell_type":"code","source":["{\"text\": \"Alice is a teacher. Bob is a student. The child is [B]. [C] is a teacher. [D] is a student. The child is\",\n","     \"S1\": \"Alice\", \"S2\": \"Bob\", \"S3\": \"Carol\", \"S4\": \"Dave\"},]"],"metadata":{"id":"znbUPnpelKOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = model.tokenizer.tokenize(\"teacher\")\n","len(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjwwqsmDlTcH","executionInfo":{"status":"ok","timestamp":1685398583951,"user_tz":240,"elapsed":179,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"058a8050-7bc9-431a-c3c9-064d53a16374"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["string = \"Alice is a teacher. Bob is a student. The child is Bob. Carol is a teacher. David is a student. The child is\"\n","target_token = \"ĠBob\"\n","\n","tokens = model.tokenizer.tokenize(string)\n","\n","if target_token in tokens:\n","    target_index = tokens.index(target_token)\n","    print(target_index)\n","else:\n","    print(\"Target token not found in the string.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZSd1z0-ldEB","executionInfo":{"status":"ok","timestamp":1685400786527,"user_tz":240,"elapsed":180,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"95a0141b-9abf-438e-84a9-3b2bfa6c4570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n"]}]},{"cell_type":"code","source":["tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83fOAibzlqc1","executionInfo":{"status":"ok","timestamp":1685400788900,"user_tz":240,"elapsed":186,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8da038d3-6264-4e2a-ce85-892ad9e7f06e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Alice',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġteacher',\n"," '.',\n"," 'ĠBob',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġstudent',\n"," '.',\n"," 'ĠThe',\n"," 'Ġchild',\n"," 'Ġis',\n"," 'ĠBob',\n"," '.',\n"," 'ĠCarol',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġteacher',\n"," '.',\n"," 'ĠDavid',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġstudent',\n"," '.',\n"," 'ĠThe',\n"," 'Ġchild',\n"," 'Ġis']"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["### New Dataset Class"],"metadata":{"id":"5XT9_LRrDsyK"}},{"cell_type":"code","source":["# test word_idx fn\n","\n","ioi_prompts = [{'text': 'Alice is a teacher. Bob is a student. The child is Bob. Carol is a teacher. David is a student. The child is',\n","  'S1': 'Alice',\n","  'S2': 'Bob',\n","  'S3': 'Carol',\n","  'S4': 'David'}]\n","\n","N=1\n","word_idx = {\"S1\": torch.tensor([1]*N)}\n","for subj in [\"S2\", \"S3\", \"S4\"]:\n","    subj_lst = []\n","    for prompt in ioi_prompts:\n","        input_text = prompt[\"text\"]\n","        target_token = \"Ġ\" + prompt[subj]\n","\n","        tokens = model.tokenizer.tokenize(input_text)\n","        target_index = tokens.index(target_token)\n","        subj_lst.append(target_index)\n","    word_idx[subj] = torch.tensor(subj_lst)\n","word_idx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dY6jMBfRpF-S","executionInfo":{"status":"ok","timestamp":1685399857020,"user_tz":240,"elapsed":160,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"23a49b33-56e1-4f02-b83f-3325d5a10aef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'S1': tensor([1]), 'S2': tensor([5]), 'S3': tensor([15]), 'S4': tensor([20])}"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, ioi_prompts, tokenizer, N):\n","        self.ioi_prompts = ioi_prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","\n","        texts = [ prompt[\"text\"] for prompt in self.ioi_prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        self.word_idx = {\"S1\": torch.tensor([1]*N)}\n","        for subj in [\"S2\", \"S3\", \"S4\"]:\n","            subj_lst = []\n","            for prompt in self.ioi_prompts:\n","                input_text = prompt[\"text\"]\n","                target_token = \"Ġ\" + prompt[subj]\n","\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = tokens.index(target_token)\n","                subj_lst.append(target_index)\n","            self.word_idx[subj] = torch.tensor(subj_lst)"],"metadata":{"id":"qau6bOQRXcrB","executionInfo":{"status":"ok","timestamp":1687966474461,"user_tz":240,"elapsed":255,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","names = [\"Alice\", \"Bob\", \"Carol\", \"David\"]\n","\n","ioi_prompts_elem = {}\n","for i, name in enumerate(names, start=1):\n","    placeholder = \"[S\" + str(i) + \"]\"\n","    template = template.replace(placeholder, name)\n","ioi_prompts_elem['text'] = template\n","\n","for i, name in enumerate(names, start=1):\n","    placeholder = \"S\" + str(i)\n","    ioi_prompts_elem[placeholder] = name\n","\n","ioi_prompts = [ioi_prompts_elem]"],"metadata":{"id":"NOm8xnEQns4t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ioi_prompts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8zQTl2MpJ4C","executionInfo":{"status":"ok","timestamp":1685399884001,"user_tz":240,"elapsed":191,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f73aad21-74a2-4844-8ba4-8e21ea77f7e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'text': 'Alice is a teacher. Bob is a student. The child is Bob. Carol is a teacher. David is a student. The child is',\n","  'S1': 'Alice',\n","  'S2': 'Bob',\n","  'S3': 'Carol',\n","  'S4': 'David'}]"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["N=1\n","dataset = Dataset(ioi_prompts, model.tokenizer, N)"],"metadata":{"id":"bpaB2l_HorlU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rewrite copy scores to not use ioi_dataset"],"metadata":{"id":"k1fLYFQ_qiKK"}},{"cell_type":"code","source":["def check_copy_circuit_2(model, layer, head, ioi_dataset, verbose=False, neg=False, print_tokens=True):\n","    cache = {}\n","    model.cache_some(cache, lambda x: x == \"blocks.0.hook_resid_post\")\n","    model(ioi_dataset.toks.long())\n","    if neg:\n","        sign = -1\n","    else:\n","        sign = 1\n","    z_0 = model.blocks[1].attn.ln1(cache[\"blocks.0.hook_resid_post\"])\n","\n","    v = torch.einsum(\"eab,bc->eac\", z_0, model.blocks[layer].attn.W_V[head])\n","    v += model.blocks[layer].attn.b_V[head].unsqueeze(0).unsqueeze(0)\n","\n","    o = sign * torch.einsum(\"sph,hd->spd\", v, model.blocks[layer].attn.W_O[head])\n","    logits = model.unembed(model.ln_final(o))\n","\n","    k = 5\n","    n_right = 0\n","\n","    S_pred_tokens = {}\n","    subjects_moved = []\n","    for seq_idx, prompt in enumerate(ioi_dataset.ioi_prompts):\n","        for word in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            pred_tokens = [\n","                model.tokenizer.decode(token)\n","                for token in torch.topk(\n","                    logits[seq_idx, ioi_dataset.word_idx[word][seq_idx]], k\n","                ).indices\n","            ]\n","            S_pred_tokens[prompt[word]] = pred_tokens\n","            # if \"S\" in word:\n","            #     name = \"S\"\n","            # else:\n","            #     name = word\n","            if \" \" + prompt[word] in pred_tokens:\n","                n_right += 1\n","                subjects_moved.append(prompt[word])\n","            # else:\n","            #     if verbose:\n","            #         print(\"-------\")\n","            #         print(\"Seq: \" + ioi_dataset.sentences[seq_idx])\n","            #         print(\"Target: \" + ioi_dataset.ioi_prompts[seq_idx][name])\n","            #         print(\n","            #             \" \".join(\n","            #                 [\n","            #                     f\"({i+1}):{model.tokenizer.decode(token)}\"\n","            #                     for i, token in enumerate(\n","            #                         torch.topk(\n","            #                             logits[\n","            #                                 seq_idx, ioi_dataset.word_idx[word][seq_idx]\n","            #                             ],\n","            #                             k,\n","            #                         ).indices\n","            #                     )\n","            #                 ]\n","            #             )\n","            #         )\n","    percent_right = (n_right / (ioi_dataset.N * 4)) * 100\n","    print(f\"Copy circuit for head {layer}.{head} (sign={sign}) : Top {k} accuracy: {percent_right}%\"  )\n","    if print_tokens == True:\n","        return S_pred_tokens\n","    else:\n","        return subjects_moved"],"metadata":{"id":"-2rIAnfFqv62","executionInfo":{"status":"ok","timestamp":1687966424182,"user_tz":240,"elapsed":232,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["check_copy_circuit_2(model, 9, 9, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWp2OMuKQmqZ","executionInfo":{"status":"ok","timestamp":1685403358824,"user_tz":240,"elapsed":1075,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"96455e85-6af0-45ef-d1cc-814b21423ba9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.9 (sign=1) : Top 5 accuracy: 75.0%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Alice': [' Titus', ' Bits', ' Ner', ' Fit', ' Kod'],\n"," 'Bob': [' Bob', 'Bob', ' bob', 'ub', 'ob'],\n"," 'Carol': [' Carol', ' CAR', ' Carroll', ' Charl', ' Carnegie'],\n"," 'David': [' David', 'David', ' david', 'avid', ' Davidson']}"]},"metadata":{},"execution_count":137}]},{"cell_type":"markdown","source":["Compare to random head"],"metadata":{"id":"iYSwhBeQrnZd"}},{"cell_type":"code","source":["check_copy_circuit_2(model, 3, 2, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sedSIw-ZrV6N","executionInfo":{"status":"ok","timestamp":1685403173236,"user_tz":240,"elapsed":664,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"fdc1a37b-3324-41f7-cf5f-758bea2e0d45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 3.2 (sign=1) : Top 5 accuracy: 0.0%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'Alice': ['atre', '装', 'yne', '中', 'ilda'],\n"," 'Bob': [' Mason', 'ovember', ' McMaster', '�', 'claw'],\n"," 'Carol': ['wat', ' Tank', ' McMaster', 'wan', 'ants'],\n"," 'David': [' QC', ' Hague', 'wat', ' Stock', ' Stevenson']}"]},"metadata":{},"execution_count":125}]},{"cell_type":"markdown","source":["## Get important heads"],"metadata":{"id":"h3Rp4RAjyZWe"}},{"cell_type":"markdown","source":["Find what heads are specific to certain inputs, and what's common to the template.\n","\n","Get important heads from:\n","\n","simple_analogies_circuits.ipynb\n","\n","https://colab.research.google.com/drive/1mhcgx2SU3GrDq3pMZp_-JPtE_fO-7kGg#scrollTo=_ChKijEui-KV&line=3&uniqifier=1\n","\n","most_recent_S_attn_pat.ipynb\n","\n","https://colab.research.google.com/drive/1KaqcS92-BI4FZ7m-r8rCW9tIovxA_s93#scrollTo=VcFgqbcF4YvI\n","\n","Positives (blue) List:\n","\n","L8, H11\n","\n","L9, H9\n","\n","\n","\n","```\n","Top value 1: Row=9, Column=9, Value=2.5532712936401367\n","Top value 2: Row=8, Column=11, Value=2.1216535568237305\n","Top value 3: Row=10, Column=6, Value=1.6274135112762451\n","Top value 4: Row=11, Column=1, Value=0.37464624643325806\n","Top value 5: Row=8, Column=6, Value=0.36867403984069824\n","```"],"metadata":{"id":"aoEXQeXhymq1"}},{"cell_type":"code","source":["top_val = [(9, 9), (8, 11), (10, 6), (11, 1), (8, 6)]\n","for layer, head in top_val:\n","    print(check_copy_circuit_2(model, layer, head, dataset, print_tokens=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmbkcjxVxNnd","executionInfo":{"status":"ok","timestamp":1685403364656,"user_tz":240,"elapsed":2359,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c6825074-2534-4636-b551-a77454704845"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.9 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 8.11 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 10.6 (sign=1) : Top 5 accuracy: 50.0%\n","['Bob', 'David']\n","Copy circuit for head 11.1 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 8.6 (sign=1) : Top 5 accuracy: 0.0%\n","[]\n"]}]},{"cell_type":"code","source":["top_val = [(9, 9), (8, 11), (10, 6), (11, 1), (8, 6), (9, 2), (2, 10), (11, 8), (8, 8), (5, 11)]\n","for index, (layer, head) in enumerate(top_val):\n","    print(index, check_copy_circuit_2(model, layer, head, dataset, print_tokens=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsbSH4Gdx6kB","executionInfo":{"status":"ok","timestamp":1685403386194,"user_tz":240,"elapsed":6319,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"97b7fad2-1e3f-4f3d-e882-9708b93523d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.9 (sign=1) : Top 5 accuracy: 75.0%\n","0 ['Bob', 'Carol', 'David']\n","Copy circuit for head 8.11 (sign=1) : Top 5 accuracy: 75.0%\n","1 ['Bob', 'Carol', 'David']\n","Copy circuit for head 10.6 (sign=1) : Top 5 accuracy: 50.0%\n","2 ['Bob', 'David']\n","Copy circuit for head 11.1 (sign=1) : Top 5 accuracy: 75.0%\n","3 ['Bob', 'Carol', 'David']\n","Copy circuit for head 8.6 (sign=1) : Top 5 accuracy: 0.0%\n","4 []\n","Copy circuit for head 9.2 (sign=1) : Top 5 accuracy: 0.0%\n","5 []\n","Copy circuit for head 2.10 (sign=1) : Top 5 accuracy: 0.0%\n","6 []\n","Copy circuit for head 11.8 (sign=1) : Top 5 accuracy: 0.0%\n","7 []\n","Copy circuit for head 8.8 (sign=1) : Top 5 accuracy: 25.0%\n","8 ['Carol']\n","Copy circuit for head 5.11 (sign=1) : Top 5 accuracy: 0.0%\n","9 []\n"]}]},{"cell_type":"markdown","source":["Find similarity of these top results to \"David\""],"metadata":{"id":"s7pYhwqCtj7N"}},{"cell_type":"markdown","source":["Look at random heads"],"metadata":{"id":"Ar6T6IiZwESA"}},{"cell_type":"code","source":["check_copy_circuit_2(model, 10, 10, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApPes0FYtLdV","executionInfo":{"status":"ok","timestamp":1685402045573,"user_tz":240,"elapsed":601,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cb97f66e-c06f-4767-ab06-c9571a8fb7e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 10.10 (sign=1) : Top 5 accuracy: 50.0%\n"]},{"output_type":"execute_result","data":{"text/plain":["(50.0, [' Del', 'Del', ' EC', ' Dak', ' De'])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["check_copy_circuit_2(model, 10, 0, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFL2qlBwt_DD","executionInfo":{"status":"ok","timestamp":1685402048366,"user_tz":240,"elapsed":658,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d9ac024d-8404-486b-f375-99ac5f76da29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 10.0 (sign=1) : Top 5 accuracy: 50.0%\n"]},{"output_type":"execute_result","data":{"text/plain":["(50.0, ['Israel', ' Israel', 'Israeli', ' Tel', ' Israeli'])"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["check_copy_circuit_2(model, 9, 0, dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RslIyQouC-B","executionInfo":{"status":"ok","timestamp":1685402050708,"user_tz":240,"elapsed":590,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d06f66bc-136b-40dc-ea9e-ea9b4c21f54c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.0 (sign=1) : Top 5 accuracy: 0.0%\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.0, [' Animation', ' CGI', ' studio', 'amera', ' clients'])"]},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["## Test if S1 isn't recognized bc Alice or if error in how S1 defined in Dataset code"],"metadata":{"id":"TsA5iT1c4Jn3"}},{"cell_type":"code","source":["def make_ioi_prompts(template, names):\n","    ioi_prompts_elem = {}\n","    for i, name in enumerate(names, start=1):\n","        placeholder = \"[S\" + str(i) + \"]\"\n","        template = template.replace(placeholder, name)\n","    ioi_prompts_elem['text'] = template\n","\n","    for i, name in enumerate(names, start=1):\n","        placeholder = \"S\" + str(i)\n","        ioi_prompts_elem[placeholder] = name\n","\n","    ioi_prompts = [ioi_prompts_elem]\n","    return ioi_prompts\n","\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","names = [\"Adam\", \"Bob\", \"Carol\", \"David\"]\n","ioi_prompts_2 = make_ioi_prompts(template, names)\n","N=1\n","dataset_2 = Dataset(ioi_prompts_2, model.tokenizer, N)"],"metadata":{"id":"caAApqM64KkA","executionInfo":{"status":"ok","timestamp":1687966487598,"user_tz":240,"elapsed":781,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["top_val = [(9, 9), (8, 11), (10, 6), (11, 1), (8, 6)]\n","for layer, head in top_val:\n","    print(check_copy_circuit_2(model, layer, head, dataset_2, print_tokens=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MaOFeq6s4Zx4","executionInfo":{"status":"ok","timestamp":1687966490336,"user_tz":240,"elapsed":381,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"70dd271d-c3ae-4920-97d7-f7f708d02610"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.9 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 8.11 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 10.6 (sign=1) : Top 5 accuracy: 50.0%\n","['Bob', 'David']\n","Copy circuit for head 11.1 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 8.6 (sign=1) : Top 5 accuracy: 25.0%\n","['Carol']\n"]}]},{"cell_type":"markdown","source":["There is an error with S1. Fix it below:"],"metadata":{"id":"waUI1Lve4i6E"}},{"cell_type":"markdown","source":["## New Dataset Class (Fixed)"],"metadata":{"id":"fiFvZO9W1WkX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, ioi_prompts, tokenizer, N):\n","        self.ioi_prompts = ioi_prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","\n","        texts = [ prompt[\"text\"] for prompt in self.ioi_prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        self.word_idx = {}\n","        for subj in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            subj_lst = []\n","            for prompt in self.ioi_prompts:\n","                input_text = prompt[\"text\"]\n","                if subj != \"S1\":  # b/c first S1 is first token, which doesn't have space\n","                    target_token = \"Ġ\" + prompt[subj]\n","                else:\n","                    target_token = prompt[subj]\n","\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = tokens.index(target_token)\n","                subj_lst.append(target_index)\n","            self.word_idx[subj] = torch.tensor(subj_lst)\n","\n","        subj_lst = []\n","        for prompt in self.ioi_prompts:\n","            input_text = prompt[\"text\"]\n","\n","            tokens = self.tokenizer.tokenize(input_text)\n","\n","            end_token_index = len(tokens) - 1\n","            subj_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(subj_lst)"],"metadata":{"id":"3oGpirrq4gQ_","executionInfo":{"status":"ok","timestamp":1687966499626,"user_tz":240,"elapsed":239,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["dataset_2_fixed = Dataset(ioi_prompts_2, model.tokenizer, N)\n","for layer, head in top_val:\n","    print(check_copy_circuit_2(model, layer, head, dataset_2_fixed, print_tokens=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyxRjg1T6oo6","executionInfo":{"status":"ok","timestamp":1687966502386,"user_tz":240,"elapsed":282,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0d33363e-239e-48ff-c68c-19e172076d5f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Copy circuit for head 9.9 (sign=1) : Top 5 accuracy: 100.0%\n","['Adam', 'Bob', 'Carol', 'David']\n","Copy circuit for head 8.11 (sign=1) : Top 5 accuracy: 75.0%\n","['Bob', 'Carol', 'David']\n","Copy circuit for head 10.6 (sign=1) : Top 5 accuracy: 50.0%\n","['Bob', 'David']\n","Copy circuit for head 11.1 (sign=1) : Top 5 accuracy: 100.0%\n","['Adam', 'Bob', 'Carol', 'David']\n","Copy circuit for head 8.6 (sign=1) : Top 5 accuracy: 25.0%\n","['Carol']\n"]}]},{"cell_type":"markdown","source":["# Writing direction results with scatterplot"],"metadata":{"id":"pc6wzXDl1G5E"}},{"cell_type":"code","source":["def make_ioi_prompts(template, names):\n","    ioi_prompts_elem = {}\n","    for i, name in enumerate(names, start=1):\n","        placeholder = \"[S\" + str(i) + \"]\"\n","        template = template.replace(placeholder, name)\n","    ioi_prompts_elem['text'] = template\n","\n","    for i, name in enumerate(names, start=1):\n","        placeholder = \"S\" + str(i)\n","        ioi_prompts_elem[placeholder] = name\n","\n","    ioi_prompts = [ioi_prompts_elem]\n","    return ioi_prompts\n","\n","class Dataset:\n","    def __init__(self, ioi_prompts, tokenizer, N):\n","        self.ioi_prompts = ioi_prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","\n","        texts = [ prompt[\"text\"] for prompt in self.ioi_prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        self.word_idx = {}\n","        for subj in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            subj_lst = []\n","            for prompt in self.ioi_prompts:\n","                input_text = prompt[\"text\"]\n","                if subj != \"S1\":  # b/c first S1 is first token, which doesn't have space\n","                    target_token = \"Ġ\" + prompt[subj]\n","                else:\n","                    target_token = prompt[subj]\n","\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = tokens.index(target_token)\n","                subj_lst.append(target_index)\n","            self.word_idx[subj] = torch.tensor(subj_lst)\n","\n","        subj_lst = []\n","        for prompt in self.ioi_prompts:\n","            input_text = prompt[\"text\"]\n","\n","            tokens = self.tokenizer.tokenize(input_text)\n","\n","            end_token_index = len(tokens) - 1\n","            subj_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(subj_lst)\n","\n","N=1\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","names = [\"Adam\", \"Bob\", \"Carol\", \"David\"]\n","ioi_prompts_2 = make_ioi_prompts(template, names)\n","dataset_2_fixed = Dataset(ioi_prompts_2, model.tokenizer, N)"],"metadata":{"id":"4wXBNWj5FwVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scatter_attention_and_contribution(\n","    model,\n","    layer_no,\n","    head_no,\n","    ioi_dataset,\n","    return_vals=False,\n","    return_fig=False,\n","):\n","    \"\"\"\n","    Plot a scatter plot\n","    for each input sequence with the attention paid to IO and S\n","    and the amount that is written in the IO and S directions\n","    \"\"\"\n","\n","    n_heads = model.cfg.n_heads\n","    n_layers = model.cfg.n_layers\n","    model_unembed = model.unembed.W_U.detach().cpu()\n","    df = []\n","    cache = {}\n","    model.cache_all(cache)\n","\n","    logits = model(ioi_dataset.toks.long())\n","\n","    for i, prompt in enumerate(ioi_dataset.ioi_prompts):\n","\n","        io_tok = model.tokenizer(\" \" + prompt[\"S3\"])[\"input_ids\"][0]\n","        s_tok = model.tokenizer(\" \" + prompt[\"S2\"])[\"input_ids\"][0]\n","        toks = model.tokenizer(prompt[\"text\"])[\"input_ids\"]\n","        io_pos = toks.index(io_tok)\n","        s1_pos = toks.index(s_tok)\n","        s2_pos = toks[s1_pos + 1 :].index(s_tok) + (s1_pos + 1)\n","        # assert toks[-1] == io_tok\n","\n","        io_dir = model_unembed[:, io_tok].detach()\n","        s_dir = model_unembed[:, s_tok].detach()\n","\n","        # model.reset_hooks() # should allow things to be done with ablated models\n","\n","        for dire, posses, tok_type in [\n","            (io_dir, [io_pos], \"S3\"),\n","            (s_dir, [s1_pos, s2_pos], \"S2\"),\n","        ]:\n","            prob = sum(\n","                [\n","                    cache[f\"blocks.{layer_no}.attn.hook_attn\"][\n","                        i, head_no, ioi_dataset.word_idx[\"end\"][i], pos\n","                    ]\n","                    .detach()\n","                    .cpu()\n","                    for pos in posses\n","                ]\n","            )\n","            resid = (\n","                cache[f\"blocks.{layer_no}.attn.hook_result\"][\n","                    i, ioi_dataset.word_idx[\"end\"][i], head_no, :\n","                ]\n","                .detach()\n","                .cpu()\n","            )\n","            dot = torch.einsum(\"a,a->\", resid, dire)\n","            df.append([prob, dot, tok_type, prompt[\"text\"]])\n","\n","    # most of the pandas stuff is intuitive, no need to deeply understand\n","    viz_df = pd.DataFrame(\n","        df, columns=[f\"Attn Prob on Name\", f\"Dot w Name Embed\", \"Name Type\", \"text\"]\n","    )\n","    fig = px.scatter(\n","        viz_df,\n","        x=f\"Attn Prob on Name\",\n","        y=f\"Dot w Name Embed\",\n","        color=\"Name Type\",\n","        hover_data=[\"text\"],\n","        color_discrete_sequence=[\"rgb(114,255,100)\", \"rgb(201,165,247)\"],\n","        title=f\"How Strong {layer_no}.{head_no} Writes in the Name Embed Direction Relative to Attn Prob\",\n","    )\n","\n","    if return_vals:\n","        return viz_df\n","    if return_fig:\n","        return fig\n","    else:\n","        fig.show()"],"metadata":{"id":"sdNIxXPz1Hu0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_2_fixed = Dataset(ioi_prompts_2, model.tokenizer, N)"],"metadata":{"id":"wZGxKV5nQHUx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scatter_attention_and_contribution(\n","    model=model, layer_no=9, head_no=9, ioi_dataset=dataset_2_fixed\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"ZcWlcvVu1fIT","executionInfo":{"status":"ok","timestamp":1685756844080,"user_tz":240,"elapsed":1246,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"301eaf9e-0557-4186-f4d3-18b405939d5b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"7fe5f299-6c1d-49ba-8c94-f969d99a62e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7fe5f299-6c1d-49ba-8c94-f969d99a62e4\")) {                    Plotly.newPlot(                        \"7fe5f299-6c1d-49ba-8c94-f969d99a62e4\",                        [{\"customdata\":[[\"Adam is a teacher. Bob is a student. The child is Bob. Carol is a teacher. David is a student. The child is\"]],\"hovertemplate\":\"Name Type=S3<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S3\",\"marker\":{\"color\":\"rgb(114,255,100)\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S3\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.08814763277769089],\"xaxis\":\"x\",\"y\":[9.022113800048828],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Adam is a teacher. Bob is a student. The child is Bob. Carol is a teacher. David is a student. The child is\"]],\"hovertemplate\":\"Name Type=S2<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S2\",\"marker\":{\"color\":\"rgb(201,165,247)\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S2\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.009677708148956299],\"xaxis\":\"x\",\"y\":[-0.11652324348688126],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Attn Prob on Name\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dot w Name Embed\"}},\"legend\":{\"title\":{\"text\":\"Name Type\"},\"tracegroupgap\":0},\"title\":{\"text\":\"How Strong 9.9 Writes in the Name Embed Direction Relative to Attn Prob\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('7fe5f299-6c1d-49ba-8c94-f969d99a62e4');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Analyze variables in scatterplot()"],"metadata":{"id":"BhIZaW096rbq"}},{"cell_type":"code","source":["\"\"\"\n","Plot a scatter plot\n","for each input sequence with the attention paid to IO and S\n","and the amount that is written in the IO and S directions\n","\"\"\"\n","layer_no=9\n","head_no=9\n","ioi_dataset=dataset_2_fixed\n","\n","n_heads = model.cfg.n_heads\n","n_layers = model.cfg.n_layers\n","model_unembed = model.unembed.W_U.detach().cpu()\n","df = []\n","cache = {}\n","model.cache_all(cache)\n","\n","logits = model(ioi_dataset.toks.long())\n","\n","for i, prompt in enumerate(ioi_dataset.ioi_prompts):\n","\n","    io_tok = model.tokenizer(\" \" + prompt[\"S3\"])[\"input_ids\"][0]\n","    s_tok = model.tokenizer(\" \" + prompt[\"S2\"])[\"input_ids\"][0]\n","    toks = model.tokenizer(prompt[\"text\"])[\"input_ids\"]\n","    io_pos = toks.index(io_tok)\n","    s1_pos = toks.index(s_tok)\n","    s2_pos = toks[s1_pos + 1 :].index(s_tok) + (s1_pos + 1)\n","    # assert toks[-1] == io_tok\n","\n","    io_dir = model_unembed[:, io_tok].detach()\n","    s_dir = model_unembed[:, s_tok].detach()\n","\n","    # model.reset_hooks() # should allow things to be done with ablated models\n","\n","    for dire, posses, tok_type in [\n","        (io_dir, [io_pos], \"S3\"),\n","        (s_dir, [s1_pos, s2_pos], \"S2\"),\n","    ]:\n","        prob = sum(\n","            [\n","                cache[f\"blocks.{layer_no}.attn.hook_attn\"][\n","                    i, head_no, ioi_dataset.word_idx[\"end\"][i], pos\n","                ]\n","                .detach()\n","                .cpu()\n","                for pos in posses\n","            ]\n","        )\n","        resid = (\n","            cache[f\"blocks.{layer_no}.attn.hook_result\"][\n","                i, ioi_dataset.word_idx[\"end\"][i], head_no, :\n","            ]\n","            .detach()\n","            .cpu()\n","        )\n","        dot = torch.einsum(\"a,a->\", resid, dire)\n","        df.append([prob, dot, tok_type, prompt[\"text\"]])\n","\n","# most of the pandas stuff is intuitive, no need to deeply understand\n","viz_df = pd.DataFrame(\n","    df, columns=[f\"Attn Prob on Name\", f\"Dot w Name Embed\", \"Name Type\", \"text\"]\n",")\n","fig = px.scatter(\n","    viz_df,\n","    x=f\"Attn Prob on Name\",\n","    y=f\"Dot w Name Embed\",\n","    color=\"Name Type\",\n","    hover_data=[\"text\"],\n","    color_discrete_sequence=[\"rgb(114,255,100)\", \"rgb(201,165,247)\"],\n","    title=f\"How Strong {layer_no}.{head_no} Writes in the Name Embed Direction Relative to Attn Prob\",\n",")\n","\n","# fig.show()"],"metadata":{"id":"mZdN3joI3lTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cache[f\"blocks.{layer_no}.attn.hook_result\"].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nD8fw4IuGEUc","executionInfo":{"status":"ok","timestamp":1686581586353,"user_tz":240,"elapsed":303,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f3246ee9-1620-463d-8f8c-9d0c2a12c154"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 12, 768])"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["The last dim is vocab size"],"metadata":{"id":"7kaPTemBGLIN"}},{"cell_type":"code","source":["s_dir.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YA5vumJtHE5-","executionInfo":{"status":"ok","timestamp":1686581850114,"user_tz":240,"elapsed":408,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0c1a678c-f6bb-429b-ffc4-32fc5a68eeea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([768])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["resid.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQpmdtxcHWcp","executionInfo":{"status":"ok","timestamp":1686581901401,"user_tz":240,"elapsed":337,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c8f562bf-bba5-4238-9027-f01df604f22b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([768])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["ioi_dataset.word_idx[\"end\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0296hVRIH2x8","executionInfo":{"status":"ok","timestamp":1686582043795,"user_tz":240,"elapsed":149,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"29781b8b-cadd-4f89-9819-f2f8bf5aa30a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([27])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["ioi_dataset.word_idx[\"end\"].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1G8FVoZIAFv","executionInfo":{"status":"ok","timestamp":1686582405514,"user_tz":240,"elapsed":148,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"3532bafa-df08-4dcd-cf5a-0f62096aaa40"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["This is a tensor of dim 1, which contains the value 27. When there are more prompts, there are more dims. Each contains the end index of the prompt."],"metadata":{"id":"hWYxnr1IJOrK"}},{"cell_type":"code","source":["model_unembed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvySBAqgNzja","executionInfo":{"status":"ok","timestamp":1686583601436,"user_tz":240,"elapsed":669,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bfbb52bc-68b7-427b-93c2-9ee875885346"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([768, 50257])"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["# Generate more prompts for dataset"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["#@title Names list\n","names = [\n","    \"Michael\",\n","    \"Christopher\",\n","    \"Jessica\",\n","    \"Matthew\",\n","    \"Ashley\",\n","    \"Jennifer\",\n","    \"Joshua\",\n","    \"Amanda\",\n","    \"Daniel\",\n","    \"David\",\n","    \"James\",\n","    \"Robert\",\n","    \"John\",\n","    \"Joseph\",\n","    \"Andrew\",\n","    \"Ryan\",\n","    \"Brandon\",\n","    \"Jason\",\n","    \"Justin\",\n","    \"Sarah\",\n","    \"William\",\n","    \"Jonathan\",\n","    \"Stephanie\",\n","    \"Brian\",\n","    \"Nicole\",\n","    \"Nicholas\",\n","    \"Anthony\",\n","    \"Heather\",\n","    \"Eric\",\n","    \"Elizabeth\",\n","    \"Adam\",\n","    \"Megan\",\n","    \"Melissa\",\n","    \"Kevin\",\n","    \"Steven\",\n","    \"Thomas\",\n","    \"Timothy\",\n","    \"Christina\",\n","    \"Kyle\",\n","    \"Rachel\",\n","    \"Laura\",\n","    \"Lauren\",\n","    \"Amber\",\n","    \"Brittany\",\n","    \"Danielle\",\n","    \"Richard\",\n","    \"Kimberly\",\n","    \"Jeffrey\",\n","    \"Amy\",\n","    \"Crystal\",\n","    \"Michelle\",\n","    \"Tiffany\",\n","    \"Jeremy\",\n","    \"Benjamin\",\n","    \"Mark\",\n","    \"Emily\",\n","    \"Aaron\",\n","    \"Charles\",\n","    \"Rebecca\",\n","    \"Jacob\",\n","    \"Stephen\",\n","    \"Patrick\",\n","    \"Sean\",\n","    \"Erin\",\n","    \"Jamie\",\n","    \"Kelly\",\n","    \"Samantha\",\n","    \"Nathan\",\n","    \"Sara\",\n","    \"Dustin\",\n","    \"Paul\",\n","    \"Angela\",\n","    \"Tyler\",\n","    \"Scott\",\n","    \"Katherine\",\n","    \"Andrea\",\n","    \"Gregory\",\n","    \"Erica\",\n","    \"Mary\",\n","    \"Travis\",\n","    \"Lisa\",\n","    \"Kenneth\",\n","    \"Bryan\",\n","    \"Lindsey\",\n","    \"Kristen\",\n","    \"Jose\",\n","    \"Alexander\",\n","    \"Jesse\",\n","    \"Katie\",\n","    \"Lindsay\",\n","    \"Shannon\",\n","    \"Vanessa\",\n","    \"Courtney\",\n","    \"Christine\",\n","    \"Alicia\",\n","    \"Cody\",\n","    \"Allison\",\n","    \"Bradley\",\n","    \"Samuel\",\n","]"],"metadata":{"id":"bLQMPm0kKIRS","cellView":"form","executionInfo":{"status":"ok","timestamp":1687966575745,"user_tz":240,"elapsed":608,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def make_latestS_prompts(names, template, num_sentences):\n","    sentences = []\n","    generated_set = set() # Ensure none of the generated sentences are the same\n","    while len(sentences) < num_sentences:\n","        unique_names = random.sample(names, k=4)\n","        temp_template = template\n","        sentence_dict = {}\n","        for i, name in enumerate(unique_names, start=1):\n","            temp_template = temp_template.replace(f\"[S{i}]\", name)\n","            sentence_dict[f'S{i}'] = name\n","        sentence_dict['text'] = temp_template\n","        if sentence_dict['text'] not in generated_set:\n","            generated_set.add(sentence_dict['text'])\n","            sentences.append(sentence_dict)\n","    return sentences\n","\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","N=10\n","latestS_prompts = make_latestS_prompts(names, template, N)\n","latestS_prompts"],"metadata":{"id":"tub8nC_9Mp6a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Look into bug about name tokens"],"metadata":{"id":"p353dKo4OtHy"}},{"cell_type":"code","source":["dataset_2 = Dataset(latestS_prompts, model.tokenizer, N)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"x6lLbcrEJ5ST","executionInfo":{"status":"error","timestamp":1685794964778,"user_tz":240,"elapsed":284,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7e357fc1-02f7-45c6-9c97-2308bc4e3168"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-4074c8baf8ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_prompts_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-4-7dd022927d0b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ioi_prompts, tokenizer, N)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0msubj_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: 'Lindsey' is not in list"]}]},{"cell_type":"code","source":["latestS_prompts[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OE94flYNOJSW","executionInfo":{"status":"ok","timestamp":1685795161190,"user_tz":240,"elapsed":131,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4221f8b5-f870-408d-943c-8d42a0e98da1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'S1': 'Lindsey',\n"," 'S2': 'Erin',\n"," 'S3': 'Michelle',\n"," 'S4': 'Bryan',\n"," 'text': 'Lindsey is a teacher. Erin is a student. The child is Erin. Michelle is a teacher. Bryan is a student. The child is'}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["tokens = model.tokenizer.tokenize(latestS_prompts[1][\"text\"])\n","target_token = latestS_prompts[1]['S1']\n","target_index = tokens.index(target_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"ZKl-TqpvOEXj","executionInfo":{"status":"error","timestamp":1685795213927,"user_tz":240,"elapsed":386,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"74faf88b-cd60-471e-9d93-2360b1a25466"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-6067735e14bc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_prompts_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_prompts_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: 'Lindsey' is not in list"]}]},{"cell_type":"code","source":["tokens = model.tokenizer.tokenize(latestS_prompts[1][\"text\"])\n","target_token = \"Ġ\" + latestS_prompts[1]['S1']\n","target_index = tokens.index(target_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"Y7y5-ZoBOeF7","executionInfo":{"status":"error","timestamp":1685795251192,"user_tz":240,"elapsed":279,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"0a5e0da6-b000-44a5-d93c-7d3c24ee48b6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-7d17a4d00153>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_prompts_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Ġ\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mioi_prompts_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: 'ĠLindsey' is not in list"]}]},{"cell_type":"markdown","source":["I assumed all the names were single token. Let's check."],"metadata":{"id":"bjHk-kvtOnUS"}},{"cell_type":"code","source":["tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-92vLUmVOrvz","executionInfo":{"status":"ok","timestamp":1685795351797,"user_tz":240,"elapsed":151,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a1807761-6c38-4a6f-8624-0e4f59e90f42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Lind',\n"," 'sey',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġteacher',\n"," '.',\n"," 'ĠErin',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġstudent',\n"," '.',\n"," 'ĠThe',\n"," 'Ġchild',\n"," 'Ġis',\n"," 'ĠErin',\n"," '.',\n"," 'ĠMichelle',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġteacher',\n"," '.',\n"," 'ĠBryan',\n"," 'Ġis',\n"," 'Ġa',\n"," 'Ġstudent',\n"," '.',\n"," 'ĠThe',\n"," 'Ġchild',\n"," 'Ġis']"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["model.tokenizer.tokenize(\"Lindsey\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWq8v9_2PG2z","executionInfo":{"status":"ok","timestamp":1685795418603,"user_tz":240,"elapsed":134,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"67ee2b22-edf7-4ecc-f861-91edfea00e21"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Lind', 'sey']"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["Thus, loop over names and remove those with more than one token"],"metadata":{"id":"yQUBZ4Y3O-OO"}},{"cell_type":"code","source":["def filter_names(names):\n","    return [name for name in names if len(model.tokenizer.tokenize(name)) == 1]\n","names = filter_names(names)"],"metadata":{"id":"_6aymEHkPUn4","executionInfo":{"status":"ok","timestamp":1687966596896,"user_tz":240,"elapsed":219,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### Make dataset after fixing single name tokens bug"],"metadata":{"id":"khhmvQhKPkL9"}},{"cell_type":"code","source":["latestS_prompts = make_latestS_prompts(names, template, N)\n","dataset_2_fixed = Dataset(latestS_prompts, model.tokenizer, N)"],"metadata":{"id":"b8HJww_CPuzj","executionInfo":{"status":"ok","timestamp":1687966599076,"user_tz":240,"elapsed":243,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["scatter_attention_and_contribution(\n","    model=model, layer_no=9, head_no=9, ioi_dataset=dataset_2_fixed\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"d2A1lkMNP2Q_","executionInfo":{"status":"ok","timestamp":1686601570229,"user_tz":240,"elapsed":2530,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a1340be1-65ed-4fde-eec0-8cbe446bdf4a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"90581370-63da-4199-bfe7-e7e7d9111ebd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"90581370-63da-4199-bfe7-e7e7d9111ebd\")) {                    Plotly.newPlot(                        \"90581370-63da-4199-bfe7-e7e7d9111ebd\",                        [{\"customdata\":[[\"Joshua is a teacher. Paul is a student. The child is Paul. Richard is a teacher. Alexander is a student. The child is\"],[\"Jennifer is a teacher. Scott is a student. The child is Scott. Michelle is a teacher. Mary is a student. The child is\"],[\"James is a teacher. Patrick is a student. The child is Patrick. Laura is a teacher. Jeremy is a student. The child is\"],[\"John is a teacher. Justin is a student. The child is Justin. Crystal is a teacher. Aaron is a student. The child is\"],[\"Thomas is a teacher. Ryan is a student. The child is Ryan. Michelle is a teacher. Scott is a student. The child is\"],[\"Paul is a teacher. Jamie is a student. The child is Jamie. Andrew is a teacher. Kelly is a student. The child is\"],[\"Jonathan is a teacher. Kevin is a student. The child is Kevin. Patrick is a teacher. Stephen is a student. The child is\"],[\"Elizabeth is a teacher. Kyle is a student. The child is Kyle. Crystal is a teacher. David is a student. The child is\"],[\"Jason is a teacher. Brandon is a student. The child is Brandon. Jennifer is a teacher. Anthony is a student. The child is\"],[\"Christopher is a teacher. Emily is a student. The child is Emily. Jeremy is a teacher. Brandon is a student. The child is\"]],\"hovertemplate\":\"Name Type=S3<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S3\",\"marker\":{\"color\":\"rgb(114,255,100)\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S3\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.2586277425289154,0.333743155002594,0.21423207223415375,0.15289220213890076,0.23330983519554138,0.2799074649810791,0.19451357424259186,0.09982697665691376,0.2516113519668579,0.24562442302703857],\"xaxis\":\"x\",\"y\":[22.86739158630371,16.227256774902344,16.92903709411621,14.693951606750488,27.68134307861328,33.798980712890625,21.060640335083008,26.9581241607666,11.513632774353027,22.187938690185547],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Joshua is a teacher. Paul is a student. The child is Paul. Richard is a teacher. Alexander is a student. The child is\"],[\"Jennifer is a teacher. Scott is a student. The child is Scott. Michelle is a teacher. Mary is a student. The child is\"],[\"James is a teacher. Patrick is a student. The child is Patrick. Laura is a teacher. Jeremy is a student. The child is\"],[\"John is a teacher. Justin is a student. The child is Justin. Crystal is a teacher. Aaron is a student. The child is\"],[\"Thomas is a teacher. Ryan is a student. The child is Ryan. Michelle is a teacher. Scott is a student. The child is\"],[\"Paul is a teacher. Jamie is a student. The child is Jamie. Andrew is a teacher. Kelly is a student. The child is\"],[\"Jonathan is a teacher. Kevin is a student. The child is Kevin. Patrick is a teacher. Stephen is a student. The child is\"],[\"Elizabeth is a teacher. Kyle is a student. The child is Kyle. Crystal is a teacher. David is a student. The child is\"],[\"Jason is a teacher. Brandon is a student. The child is Brandon. Jennifer is a teacher. Anthony is a student. The child is\"],[\"Christopher is a teacher. Emily is a student. The child is Emily. Jeremy is a teacher. Brandon is a student. The child is\"]],\"hovertemplate\":\"Name Type=S2<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S2\",\"marker\":{\"color\":\"rgb(201,165,247)\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S2\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.05078018456697464,0.0745326355099678,0.08614189922809601,0.04712693393230438,0.060354672372341156,0.02694087103009224,0.043170828372240067,0.0331927165389061,0.021014653146266937,0.027890734374523163],\"xaxis\":\"x\",\"y\":[5.138441562652588,12.70294189453125,9.594947814941406,12.90673828125,17.117656707763672,-0.2941408157348633,15.786893844604492,-3.7680490016937256,11.856245040893555,3.5328407287597656],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Attn Prob on Name\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dot w Name Embed\"}},\"legend\":{\"title\":{\"text\":\"Name Type\"},\"tracegroupgap\":0},\"title\":{\"text\":\"How Strong 9.9 Writes in the Name Embed Direction Relative to Attn Prob\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('90581370-63da-4199-bfe7-e7e7d9111ebd');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"markdown","source":["NOTE: doesn't work w/ S1 due to bug about space in front, so fix that in scatter_plot"],"metadata":{"id":"IAP7Rmz5QZxK"}},{"cell_type":"markdown","source":["## Modify scatterplot() to handle >2 subjs: Fix space in front of S1 bug"],"metadata":{"id":"s08TbntIQtFF"}},{"cell_type":"markdown","source":["Make other changes to scatter_plot to convert its focus on IO and S to S1, S2, etc."],"metadata":{"id":"r4vCEUmISJP6"}},{"cell_type":"code","source":["def scatter_attention_and_contribution(\n","    model,\n","    layer_no,\n","    head_no,\n","    ioi_dataset,\n","    return_vals=False,\n","    return_fig=False,\n","):\n","    \"\"\"\n","    Plot a scatter plot\n","    for each input sequence with the attention paid to IO and S\n","    and the amount that is written in the IO and S directions\n","    \"\"\"\n","\n","    n_heads = model.cfg.n_heads\n","    n_layers = model.cfg.n_layers\n","    model_unembed = model.unembed.W_U.detach().cpu()\n","    df = []\n","    cache = {}\n","    model.cache_all(cache)\n","\n","    logits = model(ioi_dataset.toks.long())\n","\n","    for i, prompt in enumerate(ioi_dataset.ioi_prompts):\n","\n","        s1_tok = model.tokenizer(prompt[\"S1\"])[\"input_ids\"][0]\n","        s2_tok = model.tokenizer(\" \" + prompt[\"S2\"])[\"input_ids\"][0]\n","        s3_tok = model.tokenizer(\" \" + prompt[\"S3\"])[\"input_ids\"][0]\n","        s4_tok = model.tokenizer(\" \" + prompt[\"S4\"])[\"input_ids\"][0]\n","\n","        toks = model.tokenizer(prompt[\"text\"])[\"input_ids\"]\n","        s1_pos = toks.index(s1_tok)\n","        s2_pos = toks.index(s2_tok)\n","        s3_pos = toks.index(s3_tok)\n","        s4_pos = toks.index(s4_tok)\n","\n","        s1_dir = model_unembed[:, s1_tok].detach()\n","        s2_dir = model_unembed[:, s2_tok].detach()\n","        s3_dir = model_unembed[:, s3_tok].detach()\n","        s4_dir = model_unembed[:, s4_tok].detach()\n","\n","        # model.reset_hooks() # should allow things to be done with ablated models\n","\n","        for dire, posses, tok_type in [\n","            (s1_dir, [s1_pos], \"S1\"),\n","            (s2_dir, [s2_pos], \"S2\"),\n","            (s3_dir, [s3_pos], \"S3\"),\n","            (s4_dir, [s4_pos], \"S4\"),\n","        ]:\n","            prob = sum(\n","                [\n","                    cache[f\"blocks.{layer_no}.attn.hook_attn\"][\n","                        i, head_no, ioi_dataset.word_idx[\"end\"][i], pos\n","                    ]\n","                    .detach()\n","                    .cpu()\n","                    for pos in posses\n","                ]\n","            )\n","            resid = (\n","                cache[f\"blocks.{layer_no}.attn.hook_result\"][\n","                    i, ioi_dataset.word_idx[\"end\"][i], head_no, :\n","                ]\n","                .detach()\n","                .cpu()\n","            )\n","            dot = torch.einsum(\"a,a->\", resid, dire)\n","            df.append([prob, dot, tok_type, prompt[\"text\"]])\n","\n","    # most of the pandas stuff is intuitive, no need to deeply understand\n","    viz_df = pd.DataFrame(\n","        df, columns=[f\"Attn Prob on Name\", f\"Dot w Name Embed\", \"Name Type\", \"text\"]\n","    )\n","    fig = px.scatter(\n","        viz_df,\n","        x=f\"Attn Prob on Name\",\n","        y=f\"Dot w Name Embed\",\n","        color=\"Name Type\",\n","        hover_data=[\"text\"],\n","        # color_discrete_sequence=[\"rgb(114,255,100)\", \"rgb(201,165,247)\"],\n","        title=f\"How Strong {layer_no}.{head_no} Writes in the Name Embed Direction Relative to Attn Prob\",\n","    )\n","\n","    if return_vals:\n","        return viz_df\n","    if return_fig:\n","        return fig\n","    else:\n","        fig.show()"],"metadata":{"id":"BNBxVeavKpvb","executionInfo":{"status":"ok","timestamp":1687966303408,"user_tz":240,"elapsed":249,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["scatter_attention_and_contribution(\n","    model=model, layer_no=9, head_no=9, ioi_dataset=dataset_2_fixed\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"AwhyxrN3R8xL","executionInfo":{"status":"ok","timestamp":1687966610521,"user_tz":240,"elapsed":1264,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7f01d98d-58f7-4a06-e697-f890e7683e84"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"2a5d31dc-1be4-49c2-a3eb-31b79db8523e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2a5d31dc-1be4-49c2-a3eb-31b79db8523e\")) {                    Plotly.newPlot(                        \"2a5d31dc-1be4-49c2-a3eb-31b79db8523e\",                        [{\"customdata\":[[\"Jacob is a teacher. Elizabeth is a student. The child is Elizabeth. John is a teacher. Eric is a student. The child is\"],[\"Ryan is a teacher. Patrick is a student. The child is Patrick. Sarah is a teacher. Jamie is a student. The child is\"],[\"Sean is a teacher. Stephen is a student. The child is Stephen. Jennifer is a teacher. Aaron is a student. The child is\"],[\"Jacob is a teacher. John is a student. The child is John. Michelle is a teacher. Paul is a student. The child is\"],[\"Jason is a teacher. John is a student. The child is John. Rachel is a teacher. Adam is a student. The child is\"],[\"Sarah is a teacher. Jacob is a student. The child is Jacob. Jamie is a teacher. Jeremy is a student. The child is\"],[\"Brandon is a teacher. Sean is a student. The child is Sean. Brian is a teacher. Mary is a student. The child is\"],[\"Mary is a teacher. Matthew is a student. The child is Matthew. Brandon is a teacher. Alexander is a student. The child is\"],[\"Jessica is a teacher. Jose is a student. The child is Jose. Brian is a teacher. Kevin is a student. The child is\"],[\"Sarah is a teacher. Jennifer is a student. The child is Jennifer. Ryan is a teacher. Mark is a student. The child is\"]],\"hovertemplate\":\"Name Type=S1<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S1\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S1\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.014929967001080513,0.01981089822947979,0.007404556963592768,0.009297734126448631,0.008125754073262215,0.018357982859015465,0.0030267417896538973,0.007107360754162073,0.004884497262537479,0.012472431175410748],\"xaxis\":\"x\",\"y\":[5.168302536010742,7.938083648681641,-0.084779754281044,7.108924865722656,-13.121367454528809,5.4090728759765625,-13.215704917907715,0.35697993636131287,8.597197532653809,-10.222749710083008],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Jacob is a teacher. Elizabeth is a student. The child is Elizabeth. John is a teacher. Eric is a student. The child is\"],[\"Ryan is a teacher. Patrick is a student. The child is Patrick. Sarah is a teacher. Jamie is a student. The child is\"],[\"Sean is a teacher. Stephen is a student. The child is Stephen. Jennifer is a teacher. Aaron is a student. The child is\"],[\"Jacob is a teacher. John is a student. The child is John. Michelle is a teacher. Paul is a student. The child is\"],[\"Jason is a teacher. John is a student. The child is John. Rachel is a teacher. Adam is a student. The child is\"],[\"Sarah is a teacher. Jacob is a student. The child is Jacob. Jamie is a teacher. Jeremy is a student. The child is\"],[\"Brandon is a teacher. Sean is a student. The child is Sean. Brian is a teacher. Mary is a student. The child is\"],[\"Mary is a teacher. Matthew is a student. The child is Matthew. Brandon is a teacher. Alexander is a student. The child is\"],[\"Jessica is a teacher. Jose is a student. The child is Jose. Brian is a teacher. Kevin is a student. The child is\"],[\"Sarah is a teacher. Jennifer is a student. The child is Jennifer. Ryan is a teacher. Mark is a student. The child is\"]],\"hovertemplate\":\"Name Type=S2<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S2\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S2\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.021027658134698868,0.06759679317474365,0.04789165034890175,0.014465213753283024,0.04410660266876221,0.03805853798985481,0.022624926641583443,0.03669761121273041,0.021102000027894974,0.011131121776998043],\"xaxis\":\"x\",\"y\":[8.25376033782959,12.093467712402344,10.37794017791748,2.0319418907165527,-3.1397433280944824,16.89655303955078,2.8342771530151367,7.774404525756836,-4.226024150848389,-1.2935985326766968],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Jacob is a teacher. Elizabeth is a student. The child is Elizabeth. John is a teacher. Eric is a student. The child is\"],[\"Ryan is a teacher. Patrick is a student. The child is Patrick. Sarah is a teacher. Jamie is a student. The child is\"],[\"Sean is a teacher. Stephen is a student. The child is Stephen. Jennifer is a teacher. Aaron is a student. The child is\"],[\"Jacob is a teacher. John is a student. The child is John. Michelle is a teacher. Paul is a student. The child is\"],[\"Jason is a teacher. John is a student. The child is John. Rachel is a teacher. Adam is a student. The child is\"],[\"Sarah is a teacher. Jacob is a student. The child is Jacob. Jamie is a teacher. Jeremy is a student. The child is\"],[\"Brandon is a teacher. Sean is a student. The child is Sean. Brian is a teacher. Mary is a student. The child is\"],[\"Mary is a teacher. Matthew is a student. The child is Matthew. Brandon is a teacher. Alexander is a student. The child is\"],[\"Jessica is a teacher. Jose is a student. The child is Jose. Brian is a teacher. Kevin is a student. The child is\"],[\"Sarah is a teacher. Jennifer is a student. The child is Jennifer. Ryan is a teacher. Mark is a student. The child is\"]],\"hovertemplate\":\"Name Type=S3<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S3\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S3\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.19954821467399597,0.20680318772792816,0.2437499314546585,0.16587652266025543,0.27191340923309326,0.33423668146133423,0.2018343061208725,0.2894102931022644,0.16515521705150604,0.14720477163791656],\"xaxis\":\"x\",\"y\":[11.06214714050293,22.904809951782227,12.521139144897461,20.4111328125,21.904375076293945,43.401512145996094,17.13450050354004,25.82053565979004,18.578720092773438,19.456972122192383],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"customdata\":[[\"Jacob is a teacher. Elizabeth is a student. The child is Elizabeth. John is a teacher. Eric is a student. The child is\"],[\"Ryan is a teacher. Patrick is a student. The child is Patrick. Sarah is a teacher. Jamie is a student. The child is\"],[\"Sean is a teacher. Stephen is a student. The child is Stephen. Jennifer is a teacher. Aaron is a student. The child is\"],[\"Jacob is a teacher. John is a student. The child is John. Michelle is a teacher. Paul is a student. The child is\"],[\"Jason is a teacher. John is a student. The child is John. Rachel is a teacher. Adam is a student. The child is\"],[\"Sarah is a teacher. Jacob is a student. The child is Jacob. Jamie is a teacher. Jeremy is a student. The child is\"],[\"Brandon is a teacher. Sean is a student. The child is Sean. Brian is a teacher. Mary is a student. The child is\"],[\"Mary is a teacher. Matthew is a student. The child is Matthew. Brandon is a teacher. Alexander is a student. The child is\"],[\"Jessica is a teacher. Jose is a student. The child is Jose. Brian is a teacher. Kevin is a student. The child is\"],[\"Sarah is a teacher. Jennifer is a student. The child is Jennifer. Ryan is a teacher. Mark is a student. The child is\"]],\"hovertemplate\":\"Name Type=S4<br>Attn Prob on Name=%{x}<br>Dot w Name Embed=%{y}<br>text=%{customdata[0]}<extra></extra>\",\"legendgroup\":\"S4\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"S4\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.7298427224159241,0.6766626238822937,0.672250509262085,0.801203727722168,0.6558095216751099,0.5795854330062866,0.7640340328216553,0.6476558446884155,0.7859743237495422,0.8121800422668457],\"xaxis\":\"x\",\"y\":[75.8463363647461,57.017906188964844,46.41389846801758,57.656982421875,44.08859634399414,56.11629104614258,55.763214111328125,49.902400970458984,65.64999389648438,71.24945831298828],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Attn Prob on Name\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dot w Name Embed\"}},\"legend\":{\"title\":{\"text\":\"Name Type\"},\"tracegroupgap\":0},\"title\":{\"text\":\"How Strong 9.9 Writes in the Name Embed Direction Relative to Attn Prob\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('2a5d31dc-1be4-49c2-a3eb-31b79db8523e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Correlation vals"],"metadata":{"id":"U_srDb5pnjnp"}},{"cell_type":"code","source":[],"metadata":{"id":"sl44QGfQnnZW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Copy Scores for multiple prompts"],"metadata":{"id":"0MBbP2Agg-iR"}},{"cell_type":"code","source":["def check_copy_circuit_multi(model, layer, head, ioi_dataset, verbose=False, neg=False, print_tokens=True):\n","    cache = {}\n","    model.cache_some(cache, lambda x: x == \"blocks.0.hook_resid_post\")\n","    model(ioi_dataset.toks.long())\n","    if neg:\n","        sign = -1\n","    else:\n","        sign = 1\n","    z_0 = model.blocks[1].attn.ln1(cache[\"blocks.0.hook_resid_post\"])\n","\n","    v = torch.einsum(\"eab,bc->eac\", z_0, model.blocks[layer].attn.W_V[head])\n","    v += model.blocks[layer].attn.b_V[head].unsqueeze(0).unsqueeze(0)\n","\n","    o = sign * torch.einsum(\"sph,hd->spd\", v, model.blocks[layer].attn.W_O[head])\n","    logits = model.unembed(model.ln_final(o))\n","\n","    k = 5\n","    n_right = 0\n","\n","    S_pred_tokens = {}\n","    subjects_moved = []\n","    for seq_idx, prompt in enumerate(ioi_dataset.ioi_prompts):\n","        for word in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            pred_tokens = [\n","                model.tokenizer.decode(token)\n","                for token in torch.topk(\n","                    logits[seq_idx, ioi_dataset.word_idx[word][seq_idx]], k\n","                ).indices\n","            ]\n","            S_pred_tokens[prompt[word]] = pred_tokens\n","            if \" \" + prompt[word] in pred_tokens:\n","                n_right += 1\n","                subjects_moved.append(prompt[word])\n","    percent_right = (n_right / (ioi_dataset.N * 4)) * 100\n","    print(f\"Copy circuit for head {layer}.{head} (sign={sign}) : Top {k} accuracy: {percent_right}%\"  )\n","    if print_tokens == True:\n","        return S_pred_tokens\n","    else:\n","        return subjects_moved"],"metadata":{"id":"pzZyMm8phB9E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Find what affects name mover heads"],"metadata":{"id":"s1Hzc-Gi7Hx0"}},{"cell_type":"markdown","source":["We found name mover heads. Now, we use another method to see what selects the 'most recent subject' from these name mover heads. That is, another head goes in input to name mover heads so the final calculation is influenced to favor \"David\" over the others."],"metadata":{"id":"Z97RVeFFyoyN"}},{"cell_type":"markdown","source":["Check if these name movers are the same from IOI paper. From paper, Name Mover Heads: 9.9 9.6 10.0 (figure 1)\n","\n","Yes, 9.9 is the same. But others such as 8.11 and 11.1 are absent in the attention head of the paper (figure 3b). Were they not sigf enough and just not reported? Look at the hard-coded circuit variable to see all the name movers identified (includes backup name movers in same key):"],"metadata":{"id":"s11XWc7x7T5c"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":191,"status":"ok","timestamp":1685404554411,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"BJhHVRdlskRR","outputId":"fa538116-df5d-4a0d-e980-1e3549138d3b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name mover': [(9, 9),\n","  (10, 0),\n","  (9, 6),\n","  (10, 10),\n","  (10, 6),\n","  (10, 2),\n","  (10, 1),\n","  (11, 2),\n","  (9, 7),\n","  (9, 0),\n","  (11, 9)],\n"," 'negative': [(10, 7), (11, 10)],\n"," 's2 inhibition': [(7, 3), (7, 9), (8, 6), (8, 10)],\n"," 'induction': [(5, 5), (5, 8), (5, 9), (6, 9)],\n"," 'duplicate token': [(0, 1), (0, 10), (3, 0)],\n"," 'previous token': [(2, 2), (4, 11)]}"]},"metadata":{},"execution_count":154}],"source":["CIRCUIT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gx8s6qFAsm6Z"},"outputs":[],"source":["CIRCUIT_NEW = {'adjective mover': [(30, 13)]}"]},{"cell_type":"markdown","source":["See how S-inhibitions found:\n","\n","https://colab.research.google.com/drive/1YM-0MPw0KKKkjRU855Js3HxBHDgePL1S#scrollTo=ysfYnoon4uuN"],"metadata":{"id":"Ai6IcUjeHLol"}},{"cell_type":"markdown","metadata":{"id":"PIQxhkuV4uuM"},"source":["# Path patching"]},{"cell_type":"markdown","metadata":{"id":"l3pfar6esaQz"},"source":["**do_circuit_extraction**(): Add hooks to the model to obtain intermediate activations when running path patching, copy scores, etc"]},{"cell_type":"markdown","source":["## Re-run the following if restarting notebook run"],"metadata":{"id":"SQGsnfqCzLeb"}},{"cell_type":"code","source":["#@title Names list\n","names = [\n","    \"Michael\",\n","    \"Christopher\",\n","    \"Jessica\",\n","    \"Matthew\",\n","    \"Ashley\",\n","    \"Jennifer\",\n","    \"Joshua\",\n","    \"Amanda\",\n","    \"Daniel\",\n","    \"David\",\n","    \"James\",\n","    \"Robert\",\n","    \"John\",\n","    \"Joseph\",\n","    \"Andrew\",\n","    \"Ryan\",\n","    \"Brandon\",\n","    \"Jason\",\n","    \"Justin\",\n","    \"Sarah\",\n","    \"William\",\n","    \"Jonathan\",\n","    \"Stephanie\",\n","    \"Brian\",\n","    \"Nicole\",\n","    \"Nicholas\",\n","    \"Anthony\",\n","    \"Heather\",\n","    \"Eric\",\n","    \"Elizabeth\",\n","    \"Adam\",\n","    \"Megan\",\n","    \"Melissa\",\n","    \"Kevin\",\n","    \"Steven\",\n","    \"Thomas\",\n","    \"Timothy\",\n","    \"Christina\",\n","    \"Kyle\",\n","    \"Rachel\",\n","    \"Laura\",\n","    \"Lauren\",\n","    \"Amber\",\n","    \"Brittany\",\n","    \"Danielle\",\n","    \"Richard\",\n","    \"Kimberly\",\n","    \"Jeffrey\",\n","    \"Amy\",\n","    \"Crystal\",\n","    \"Michelle\",\n","    \"Tiffany\",\n","    \"Jeremy\",\n","    \"Benjamin\",\n","    \"Mark\",\n","    \"Emily\",\n","    \"Aaron\",\n","    \"Charles\",\n","    \"Rebecca\",\n","    \"Jacob\",\n","    \"Stephen\",\n","    \"Patrick\",\n","    \"Sean\",\n","    \"Erin\",\n","    \"Jamie\",\n","    \"Kelly\",\n","    \"Samantha\",\n","    \"Nathan\",\n","    \"Sara\",\n","    \"Dustin\",\n","    \"Paul\",\n","    \"Angela\",\n","    \"Tyler\",\n","    \"Scott\",\n","    \"Katherine\",\n","    \"Andrea\",\n","    \"Gregory\",\n","    \"Erica\",\n","    \"Mary\",\n","    \"Travis\",\n","    \"Lisa\",\n","    \"Kenneth\",\n","    \"Bryan\",\n","    \"Lindsey\",\n","    \"Kristen\",\n","    \"Jose\",\n","    \"Alexander\",\n","    \"Jesse\",\n","    \"Katie\",\n","    \"Lindsay\",\n","    \"Shannon\",\n","    \"Vanessa\",\n","    \"Courtney\",\n","    \"Christine\",\n","    \"Alicia\",\n","    \"Cody\",\n","    \"Allison\",\n","    \"Bradley\",\n","    \"Samuel\",\n","]\n","\n","def filter_names(names):\n","    return [name for name in names if len(model.tokenizer.tokenize(name)) == 1]\n","names = filter_names(names)"],"metadata":{"cellView":"form","id":"3mo2XJmW1OhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, ioi_prompts, tokenizer, N):\n","        self.ioi_prompts = ioi_prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","\n","        texts = [ prompt[\"text\"] for prompt in self.ioi_prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        self.word_idx = {}\n","        for subj in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            subj_lst = []\n","            for prompt in self.ioi_prompts:\n","                input_text = prompt[\"text\"]\n","                if subj != \"S1\":  # b/c first S1 is first token, which doesn't have space\n","                    target_token = \"Ġ\" + prompt[subj]\n","                else:\n","                    target_token = prompt[subj]\n","\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = tokens.index(target_token)\n","                subj_lst.append(target_index)\n","            self.word_idx[subj] = torch.tensor(subj_lst)\n","\n","        subj_lst = []\n","        for prompt in self.ioi_prompts:\n","            input_text = prompt[\"text\"]\n","\n","            tokens = self.tokenizer.tokenize(input_text)\n","\n","            end_token_index = len(tokens) - 1\n","            subj_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(subj_lst)"],"metadata":{"id":"40GQeS79zPI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def make_latestS_prompts(names, template, num_sentences):\n","    sentences = []\n","    generated_set = set() # Ensure none of the generated sentences are the same\n","    while len(sentences) < num_sentences:\n","        unique_names = random.sample(names, k=4)\n","        temp_template = template\n","        sentence_dict = {}\n","        for i, name in enumerate(unique_names, start=1):\n","            temp_template = temp_template.replace(f\"[S{i}]\", name)\n","            sentence_dict[f'S{i}'] = name\n","        sentence_dict['text'] = temp_template\n","        if sentence_dict['text'] not in generated_set:\n","            generated_set.add(sentence_dict['text'])\n","            sentences.append(sentence_dict)\n","    return sentences\n","\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","N=10\n","latestS_prompts = make_latestS_prompts(names, template, N)\n","dataset_orig = Dataset(latestS_prompts, model.tokenizer, N)"],"metadata":{"id":"z7SLU6kFzljm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run path patching after obtaining dataset making code above"],"metadata":{"id":"eh08P7BhzSQv"}},{"cell_type":"code","source":["# we make the ABC dataset in order to knockout other model components\n","# abc_dataset = (  # TODO seeded\n","#     ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n","#     .gen_flipped_prompts((\"S\", \"RAND\"))\n","#     .gen_flipped_prompts((\"S1\", \"RAND\"))\n","# )\n","\n","# switch order of target sentence\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S4] is a student. [S3] is a teacher. The child is\"\n","names = [\"Adam\", \"Bob\", \"Carol\", \"David\"]\n","latestS_prompts = make_latestS_prompts(names, template, N)\n","dataset_corr = Dataset(latestS_prompts, model.tokenizer, N)"],"metadata":{"id":"AaX0SPhLzYZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":187,"status":"error","timestamp":1687215455999,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"wGCluDzZ4uuM","outputId":"26280ebd-e88d-4573-dfaf-9fa8e6d58bb2"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-cdd387a71cf8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model, _ = do_circuit_extraction(\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_heads_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_orig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_heads_circuit\u001b[0;34m(ioi_dataset, excluded, mlp0, circuit)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_extracted_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRELEVANT_TOKENS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmlp0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_extracted_idx\u001b[0;34m(idx_list, ioi_dataset)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_extracted_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mint_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'sentences'"]}],"source":["circuit = deepcopy(CIRCUIT)\n","\n","# we then add hooks to the model to knockout all the heads except the circuit\n","model.reset_hooks()\n","model, _ = do_circuit_extraction(\n","    model=model,\n","    heads_to_keep=get_heads_circuit(ioi_dataset=dataset_orig, circuit=circuit),\n","    mlps_to_remove={},\n","    ioi_dataset=dataset_orig,\n","    mean_dataset=dataset_corr,\n",")\n","\n","circuit_logit_diff = logit_diff(model, dataset)\n","print(\n","    f\"The circuit gets average logit difference {circuit_logit_diff.item()} over {N} examples\"\n",")"]},{"cell_type":"markdown","source":["Now we require more variables. This shows just 'sentences', so add it to Dataset\n","\n","https://github.com/redwoodresearch/Easy-Transformer/blob/main/easy_transformer/ioi_circuit_extraction.py#L152"],"metadata":{"id":"-Id54ENp9M8_"}},{"cell_type":"code","source":["N=10\n","custom_templates = [\n","    \" The human is [A]. The animal is [B]. The human is\",\n","]\n","ioi_dataset = IOIDataset(prompt_type=custom_templates, N=N, tokenizer=model.tokenizer, prepend_bos=False)\n","ioi_dataset.sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1t0i_Gj9S9I","executionInfo":{"status":"ok","timestamp":1685405052876,"user_tz":240,"elapsed":341,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"992a693e-7847-4236-ad92-340dee043b11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_dataset.py:501: UserWarning: S2 index has been computed as the same for S and S2\n","  warnings.warn(\"S2 index has been computed as the same for S and S2\")\n"]},{"output_type":"execute_result","data":{"text/plain":["[' The human is Amanda. The animal is Adam. The human is',\n"," ' The human is Daniel. The animal is Bradley. The human is',\n"," ' The human is Paul. The animal is Jonathan. The human is',\n"," ' The human is Vanessa. The animal is Rachel. The human is',\n"," ' The human is Ryan. The animal is Megan. The human is',\n"," ' The human is Andrea. The animal is Paul. The human is',\n"," ' The human is Shannon. The animal is Lisa. The human is',\n"," ' The human is Amber. The animal is David. The human is',\n"," ' The human is Heather. The animal is Dustin. The human is',\n"," ' The human is Jeremy. The animal is Nicole. The human is']"]},"metadata":{},"execution_count":157}]},{"cell_type":"code","source":["ioi_prompts[0]['text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"pvequiMo-JSA","executionInfo":{"status":"ok","timestamp":1685405098378,"user_tz":240,"elapsed":369,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a3cb85fc-64e4-400a-cb75-bce13c4e0c4a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Alice is a teacher. Bob is a student. The child is Bob. Carol is a teacher. David is a student. The child is'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":160}]},{"cell_type":"markdown","source":["## Update Dataset class to include 'sentences'"],"metadata":{"id":"WvT0Y6gl7sT_"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, ioi_prompts, tokenizer, N):\n","        self.ioi_prompts = ioi_prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","        self.sentences = [ ioi_prompts[0]['text'] ]\n","\n","        texts = [ prompt[\"text\"] for prompt in self.ioi_prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        self.word_idx = {}\n","        for subj in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            subj_lst = []\n","            for prompt in self.ioi_prompts:\n","                input_text = prompt[\"text\"]\n","                if subj != \"S1\":  # b/c first S1 is first token, which doesn't have space\n","                    target_token = \"Ġ\" + prompt[subj]\n","                else:\n","                    target_token = prompt[subj]\n","\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = tokens.index(target_token)\n","                subj_lst.append(target_index)\n","            self.word_idx[subj] = torch.tensor(subj_lst)\n","\n","        subj_lst = []\n","        for prompt in self.ioi_prompts:\n","            input_text = prompt[\"text\"]\n","\n","            tokens = self.tokenizer.tokenize(input_text)\n","\n","            end_token_index = len(tokens) - 1\n","            subj_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(subj_lst)"],"metadata":{"id":"DPBQj_DjhtAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After modifying Dataset to include 'sentences', re-create the datasets"],"metadata":{"id":"aakMik1F4Tsi"}},{"cell_type":"code","source":["# %debug\n","circuit = deepcopy(CIRCUIT)\n","\n","N = 1\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","prompts = make_latestS_prompts(names, template, N)\n","dataset = Dataset(prompts, model.tokenizer, N)\n","\n","# switch order of target sentence\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S4] is a student. [S3] is a teacher. The child is\"\n","corr_prompts = make_latestS_prompts(names, template, N)\n","dataset_corr = Dataset(corr_prompts, model.tokenizer, N)\n","\n","# we then add hooks to the model to knockout all the heads except the circuit\n","model.reset_hooks()\n","model, _ = do_circuit_extraction(\n","    model=model,\n","    heads_to_keep=get_heads_circuit(ioi_dataset=dataset, circuit=circuit),\n","    mlps_to_remove={},\n","    ioi_dataset=dataset,\n","    mean_dataset=dataset_corr,\n",")\n","\n","circuit_logit_diff = logit_diff(model, dataset)\n","print(\n","    f\"The circuit gets average logit difference {circuit_logit_diff.item()} over {N} examples\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":911},"id":"NKSDVpJzAsPt","executionInfo":{"status":"error","timestamp":1687216073558,"user_tz":240,"elapsed":327,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8d4cac04-7eee-4940-ec80-af5862703d28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'S1': tensor([0]), 'S2': tensor([5]), 'S3': tensor([15]), 'S4': tensor([20]), 'end': tensor([27])} S+1\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_extracted_idx\u001b[0;34m(idx_list, ioi_dataset)\u001b[0m\n\u001b[1;32m    156\u001b[0m             int_idx_to_add = [\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             ]  # torch to python objects\n","\u001b[0;31mKeyError\u001b[0m: 'S+1'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-5230506af133>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model, _ = do_circuit_extraction(\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_heads_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_heads_circuit\u001b[0;34m(ioi_dataset, excluded, mlp0, circuit)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_extracted_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRELEVANT_TOKENS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmlp0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_extracted_idx\u001b[0;34m(idx_list, ioi_dataset)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0;34mf\"Index {idx_name} not found in the dataset. Please check the spelling and make sure the index is in the dataset.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Index S+1 not found in the dataset. Please check the spelling and make sure the index is in the dataset."]}]},{"cell_type":"markdown","source":["See traceback:\n","\n","do_circuit_extraction( THEN PASS AS ARG: get_heads_circuit() -> get_extracted_idx(RELEVANT_TOKENS) )\n","\n","https://github.com/redwoodresearch/Easy-Transformer/blob/main/easy_transformer/ioi_circuit_extraction.py#L161\n","\n","get_heads_circuit():\n","`heads_to_keep[head] = get_extracted_idx(RELEVANT_TOKENS[head], ioi_dataset)`\n","\n","get_extracted_idx(RELEVANT_TOKENS):\n","```\n","# idx_list := RELEVANT_TOKENS\n","for idx_name in idx_list:\n","        try:\n","            int_idx_to_add = [\n","                int(x) for x in list(ioi_dataset.word_idx[idx_name])\n","            ]  # torch to python objects\n","```\n","\n","RELEVANT_TOKENS:\n","https://github.com/redwoodresearch/Easy-Transformer/blob/94ed3599b17209c69eb96973c8b61d8ee98a9dc9/easy_transformer/ioi_circuit_extraction.py#L205\n","\n","head comes from the keys in CIRCUIT. Each head is (L, h).\n","https://github.com/redwoodresearch/Easy-Transformer/blob/94ed3599b17209c69eb96973c8b61d8ee98a9dc9/easy_transformer/ioi_circuit_extraction.py#L168\n","\n","idx_list uses the constant RELEVANT_TOKENS, which translates the circuit class into the query token it works on (figure 1). This is done by getting it for each [head]. We can either fork the project and manually alter this hard-coding, or we can write smaller custom functions in this nb.\n","\n","idx_name is just a string of the token. It's a value for RELEVANT_TOKENS[head]. RELEVANT_TOKENS says what TYPES of query tokens \"activate highly\" for that head. For instance, head (9,9) is mapped to \"end\" through RELEVANT_TOKENS.\n","\n","CIRCUIT specifies the type of head, while RELEVANT_TOKENS specifies the query token position (dest)."],"metadata":{"id":"UTQe9VjkDD6L"}},{"cell_type":"code","source":["# this contains token positions for that token type\n","dataset.word_idx"],"metadata":{"id":"iLE8YmMgDDeZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686690774374,"user_tz":240,"elapsed":217,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bdafe02b-01f4-4c49-8e23-420839409de9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'S1': tensor([0]),\n"," 'S2': tensor([5]),\n"," 'S3': tensor([15]),\n"," 'S4': tensor([20]),\n"," 'end': tensor([27])}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["RELEVANT_TOKENS can be modified for the 4 subjs. We may not need S+1 because right now we are only concerned with name mover heads (which is mapped to \"end\") and s1-, s2-, and s3-inhibition heads (which are also mapped to \"end\"). In the circuit, only previous_token heads are mapped to \"S+1\"; we don't look at them for now.\n","\n","To change RELEVANT_TOKENS, fork the repo and use your new repo with the modified RELEVANT_TOKENS. Alternatively, just upload the file with the new change (since it's so small). Download the old file to mod.\n","\n","One strange thing is how did they know the type of heads already if they haven't found the circuit yet? Perhaps it wasn't found with path patching, but just actv patching."],"metadata":{"id":"PB3jRKuennZ3"}},{"cell_type":"markdown","source":["## Run after modifying RELEVANT_TOKENS\n","\n","After modifying newly forked repo: In RELEVANT_TOKENS, comment all out except RELEVANT_TOKENS[head] = [\"end\"] . Then commit ioi_circuit_extraction.py and try do_circuit_extraction() again"],"metadata":{"id":"frQBjWOh5ZW8"}},{"cell_type":"code","source":["# %debug\n","circuit = deepcopy(CIRCUIT)\n","\n","N = 1\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","prompts = make_latestS_prompts(names, template, N)\n","dataset = Dataset(prompts, model.tokenizer, N)\n","\n","# switch order of target sentence\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S4] is a student. [S3] is a teacher. The child is\"\n","corr_prompts = make_latestS_prompts(names, template, N)\n","dataset_corr = Dataset(corr_prompts, model.tokenizer, N)\n","\n","# we then add hooks to the model to knockout all the heads except the circuit\n","model.reset_hooks()\n","model, _ = do_circuit_extraction(\n","    model=model,\n","    heads_to_keep=get_heads_circuit(ioi_dataset=dataset, circuit=circuit),\n","    mlps_to_remove={},\n","    ioi_dataset=dataset,\n","    mean_dataset=dataset_corr,\n",")\n","\n","circuit_logit_diff = logit_diff(model, dataset)\n","print(\n","    f\"The circuit gets average logit difference {circuit_logit_diff.item()} over {N} examples\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"KBa2zSc95cD7","executionInfo":{"status":"error","timestamp":1687216418648,"user_tz":240,"elapsed":404,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bec761b4-53cb-4b5a-8c5c-99cb530b85e8"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-5230506af133>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model, _ = do_circuit_extraction(\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_heads_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_heads_circuit\u001b[0;34m(ioi_dataset, excluded, mlp0, circuit)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_extracted_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRELEVANT_TOKENS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmlp0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: (5, 5)"]}]},{"cell_type":"markdown","source":["This bug is due to RELEVANT_TOKENS not containing the key (5,5) from\n","\n","```\n","\"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n","```\n","in CIRCUIT, so in CIRCUIT comment out all the head types you commented in RELEVANT_TOKENS then commit again.\n"],"metadata":{"id":"IdJnx0xT79l8"}},{"cell_type":"code","source":["# %debug\n","circuit = deepcopy(CIRCUIT)\n","\n","N = 1\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","prompts = make_latestS_prompts(names, template, N)\n","dataset = Dataset(prompts, model.tokenizer, N)\n","\n","# switch order of target sentence\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S4] is a student. [S3] is a teacher. The child is\"\n","corr_prompts = make_latestS_prompts(names, template, N)\n","dataset_corr = Dataset(corr_prompts, model.tokenizer, N)\n","\n","# we then add hooks to the model to knockout all the heads except the circuit\n","model.reset_hooks()\n","model, _ = do_circuit_extraction(\n","    model=model,\n","    heads_to_keep=get_heads_circuit(ioi_dataset=dataset, circuit=circuit),\n","    mlps_to_remove={},\n","    ioi_dataset=dataset,\n","    mean_dataset=dataset_corr,\n",")\n","\n","circuit_logit_diff = logit_diff(model, dataset)\n","print(\n","    f\"The circuit gets average logit difference {circuit_logit_diff.item()} over {N} examples\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":945},"id":"rPQG6ApH8e1-","executionInfo":{"status":"error","timestamp":1687216963013,"user_tz":240,"elapsed":2123,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"2e3c3219-9ff0-4463-a06b-8c231bca2126"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-5230506af133>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# we then add hooks to the model to knockout all the heads except the circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m model, _ = do_circuit_extraction(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_heads_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mdo_circuit_extraction\u001b[0;34m(heads_to_remove, mlps_to_remove, heads_to_keep, mlps_to_keep, ioi_dataset, mean_dataset, model, metric, excluded, return_hooks, hooks_dict)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;31m# check if we are either in keep XOR remove move from the args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     ablation, heads, mlps = get_circuit_replacement_hook(\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mheads_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheads_to_remove\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# {(2,3) : List[List[int]]: dimensions dataset_size * datapoint_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# {2: List[List[int]]: dimensions dataset_size * datapoint_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mget_circuit_replacement_hook\u001b[0;34m(heads_to_remove, mlps_to_remove, heads_to_keep, mlps_to_keep, heads_to_remove2, mlps_to_remove2, heads_to_keep2, mlps_to_keep2, ioi_dataset, model)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m ):\n\u001b[0;32m---> 94\u001b[0;31m     heads, mlps = process_heads_and_mlps(\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mheads_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheads_to_remove\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# {(2,3) : List[List[int]]: dimensions dataset_size * datapoint_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlps_to_remove\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# {2: List[List[int]]: dimensions dataset_size * datapoint_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mprocess_heads_and_mlps\u001b[0;34m(heads_to_remove, mlps_to_remove, heads_to_keep, mlps_to_keep, ioi_dataset, model)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mheads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mturn_keep_into_rmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# print(mlps, heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'max_len'"]}]},{"cell_type":"markdown","source":["## Update Dataset to have max_len and groups"],"metadata":{"id":"0JPi3E3s-PaH"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, ioi_prompts, tokenizer, N):\n","        self.ioi_prompts = ioi_prompts\n","        self.tokenizer = tokenizer\n","        self.N = N\n","        self.sentences = [\n","            prompt[\"text\"] for prompt in self.ioi_prompts\n","        ]  # a list of strings. Renamed as this should NOT be forward passed\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.ioi_prompts\n","            ]\n","        )\n","\n","        # add in ioi_prompt[\"TEMPLATE_IDX\"] = temp_id from def gen_prompt_uniform()\n","\n","\n","        all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        small_groups = []\n","        for group in self.groups:\n","            if len(group) < 5:\n","                small_groups.append(len(group))\n","        if len(small_groups) > 0:\n","            warnings.warn(\n","                f\"Some groups have less than 5 prompts, they have lengths {small_groups}\"\n","            )\n","\n","        texts = [ prompt[\"text\"] for prompt in self.ioi_prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","\n","        self.word_idx = {}\n","        for subj in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n","            subj_lst = []\n","            for prompt in self.ioi_prompts:\n","                input_text = prompt[\"text\"]\n","                if subj != \"S1\":  # b/c first S1 is first token, which doesn't have space\n","                    target_token = \"Ġ\" + prompt[subj]\n","                else:\n","                    target_token = prompt[subj]\n","\n","                tokens = model.tokenizer.tokenize(input_text)\n","                target_index = tokens.index(target_token)\n","                subj_lst.append(target_index)\n","            self.word_idx[subj] = torch.tensor(subj_lst)\n","\n","        subj_lst = []\n","        for prompt in self.ioi_prompts:\n","            input_text = prompt[\"text\"]\n","\n","            tokens = self.tokenizer.tokenize(input_text)\n","\n","            end_token_index = len(tokens) - 1\n","            subj_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(subj_lst)"],"metadata":{"id":"OKrnexww9-oW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %debug\n","circuit = deepcopy(CIRCUIT)\n","\n","N = 1\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S3] is a teacher. [S4] is a student. The child is\"\n","prompts = make_latestS_prompts(names, template, N)\n","dataset = Dataset(prompts, model.tokenizer, N)\n","\n","# switch order of target sentence\n","template = \"[S1] is a teacher. [S2] is a student. The child is [S2]. [S4] is a student. [S3] is a teacher. The child is\"\n","corr_prompts = make_latestS_prompts(names, template, N)\n","dataset_corr = Dataset(corr_prompts, model.tokenizer, N)\n","\n","# we then add hooks to the model to knockout all the heads except the circuit\n","model.reset_hooks()\n","model, _ = do_circuit_extraction(\n","    model=model,\n","    heads_to_keep=get_heads_circuit(ioi_dataset=dataset, circuit=circuit),\n","    mlps_to_remove={},\n","    ioi_dataset=dataset,\n","    mean_dataset=dataset_corr,\n",")\n","\n","circuit_logit_diff = logit_diff(model, dataset)\n","print(\n","    f\"The circuit gets average logit difference {circuit_logit_diff.item()} over {N} examples\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":474},"id":"j5yGVI0_-j6x","executionInfo":{"status":"error","timestamp":1687217139907,"user_tz":240,"elapsed":398,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"97a99aa9-a294-4b8f-d248-7dde97189455"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-5230506af133>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# we then add hooks to the model to knockout all the heads except the circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m model, _ = do_circuit_extraction(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mheads_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_heads_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easy_transformer/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36mdo_circuit_extraction\u001b[0;34m(heads_to_remove, mlps_to_remove, heads_to_keep, mlps_to_keep, ioi_dataset, mean_dataset, model, metric, excluded, return_hooks, hooks_dict)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0msemantic_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# ioi_dataset.sem_tok_idx,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mmean_by_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# TO CHECK CIRCUIT BY GROUPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     )\n\u001b[1;32m    320\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'groups'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"S-mc7pzQ-vcE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now try N=10"],"metadata":{"id":"v4Ol0pFL6m85"}},{"cell_type":"markdown","metadata":{"id":"KWg1JNNpxugn"},"source":["## FOR LATER AFTER FIX CIRCUIT EXTRACTION\n","\n","Iterates over each layer:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jiBA6dqK4uuM","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"error","timestamp":1685395506748,"user_tz":240,"elapsed":1644,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7e3648be-ac95-468a-b043-f530621a6d8e"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/30 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-2bbaf27cae94>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m plot_path_patching(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2bbaf27cae94>\u001b[0m in \u001b[0;36mplot_path_patching\u001b[0;34m(model, ioi_dataset, receiver_hooks, position)\u001b[0m\n\u001b[1;32m     15\u001b[0m             model = path_patching(\n\u001b[1;32m     16\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mD_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mD_orig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioi_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msender_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_head_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'corr_dataset' is not defined"]}],"source":["def plot_path_patching(\n","    model,\n","    ioi_dataset,\n","    receiver_hooks,  # list of tuples (hook_name, idx). If idx is not None, then at dim 2 index in with idx (used for doing things for specific attention heads)\n","    position,\n","):\n","    model.reset_hooks()\n","    default_logit_diff = logit_diff(model, ioi_dataset)\n","    results = torch.zeros(size=(30, 30))  # change this to 30 x 30 for large\n","    mlp_results = torch.zeros(size=(30, 1))\n","    for source_layer in tqdm(range(30)):\n","        for source_head_idx in [None] + list(range(30)):\n","            model.reset_hooks()\n","\n","            model = path_patching(\n","                model=model,\n","                D_new=dataset_corr,\n","                D_orig=ioi_dataset,\n","                sender_heads=[(source_layer, source_head_idx)],\n","                receiver_hooks=receiver_hooks,\n","                positions=[position],\n","                return_hooks=False,\n","                freeze_mlps=False,\n","                have_internal_interactions=False,\n","            )\n","            cur_logit_diff = logit_diff(model, ioi_dataset)\n","\n","            if source_head_idx is None:\n","                mlp_results[source_layer] = cur_logit_diff - default_logit_diff\n","            else:\n","                results[source_layer][source_head_idx] = (\n","                    cur_logit_diff - default_logit_diff\n","                )\n","\n","            if source_layer == 1:\n","                assert not torch.allclose(results, 0.0 * results), results\n","\n","            if source_layer == 29 and source_head_idx == 29:  # chagne to 29 for large\n","                results /= default_logit_diff\n","                mlp_results /= default_logit_diff\n","\n","                results *= 100\n","                mlp_results *= 100\n","\n","                # show attention head results\n","                fig = show_pp(\n","                    results,\n","                    title=f\"Effect of patching (Heads->Final Residual Stream State) path\",\n","                    return_fig=True,\n","                    show_fig=False,\n","                    bartitle=\"% change in logit difference\",\n","                )\n","                fig.show()\n","\n","\n","plot_path_patching(\n","    model,\n","    dataset,\n","    receiver_hooks=[(f\"blocks.{model.cfg.n_layers-1}.hook_resid_post\", None)],\n","    position=\"end\",\n",")"]}]}